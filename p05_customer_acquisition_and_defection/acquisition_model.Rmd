---
title: "R Notebook"
output: html_notebook
---

<<<<<<< HEAD
##DATA MANAGEMENT
Check the structure of the data provided.
=======

### Configure Enviornment
```{r, warning=FALSE}
library(ggplot2)
library(caret)
library(survival)
library(survminer)
```

### Load Data
>>>>>>> 6d99ffc4bc1a9cfe8faf9ab35295851b75e60f21
```{r}
# read data
df <- read.csv("Acquisition and Defection Data.csv")

# show as sample of the data
head(df)

# show the structure of the data
str(df)

# convert variables to factors
cols <- c("Acquisition", "Retention", "Industry")
df[cols] <- lapply(df[cols], factor)

# create variable names
levels(df$Acquisition) <- make.names(c("No", "Yes"))
levels(df$Retention) <- make.names(c("No", "Yes"))
levels(df$Industry) <- make.names(c("No", "Yes"))

# delete X column from df
df$X <- NULL
```

##QUESTION 1:  ACQUISTION MODELING
=======

### Predict Acquisition
Logistic model:
```{r}
# fit inital logstic regression model to predict acquisitoin
fit <- train(Acquisition ~ Acq_Expense + Industry + Revenue + Employees,
             data=df, 
             method="glm",
             family="binomial")

# show the results of the model
summary(fit)

# show which variables are important
varImp(fit)

```


Tree Model:
```{r}
# set up control for cross-validation
ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 5,
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary)

# run tree-bagging model
set.seed(1234)
tree_fit <- train(Acquisition ~ Acq_Expense + Industry + Revenue + Employees,
                  data=df, 
                  method = "treebag",
                  nbagg = 50,
                  metric = "ROC",
                  trControl = ctrl)

# show the results of the model
tree_fit

# show which variables are important
varImp(tree_fit)

```


##QUESTION 2:  CHURN MODELING
=======

### Predict churn

Logistic Model:
```{r}
#Get rid of noncustomers
df_churn <- subset(x = df, subset = (df$Acquisition=="Yes"))


# sort df by Future_CLV and look for issue with variables causing perfect seperation
df_churn <- df_churn[order(df_churn$Future_CLV),]
ggplot(data = df_churn) +
  geom_point(mapping = aes(x = seq(1, length(df_churn$Future_CLV)), y = Future_CLV, color = Retention)) + 
  ggtitle("Future CLV vs. Rention for Acquired Customers") +
  labs(x = "Rank",y = "Future CLV") +
  theme(plot.title = element_text(lineheight = 0.8, face = "bold", hjust = 0.5)) +
  theme(legend.position = c(0.1, 0.85))


# look for issues with frequency causing perfect seperation
ggplot(data = df_churn) + 
  geom_bar(mapping = aes(x = Frequency, fill = Retention)) +
  facet_wrap(~ Retention) + 
  ggtitle("Frequency vs Retention for Acquired Customers") +
  theme(plot.title = element_text(lineheight = 0.8, face = "bold", hjust = 0.5))


#Run initial churn logistic model with all vars
## PROBLEM OF PERFECT SEPARATION IN FUTURE_CLV AND FREQUENCY
## The error is different for Future_CLV vs. Frequency.  I agree that Future_CLV is prefect seperation, but I think the warning with
## frequency is related to predicted probabilities of 0 or 1.  Even though the warning comes up, the model still runs and results can
## be seen in the summary
churn_fit1 <- train( Retention ~ Industry + Revenue + Employees + Ret_Expense + First_Purchase + Acq_Expense + Breadth + Frequency,
                     data=df_churn, 
                     method="glm",
                     family = binomial(link = "logit"))


# show the results of the model
churn_fit1
summary(churn_fit1)


# show which variables are important
varImp(churn_fit1)

```

Survival Model:
```{r}
#Fit survival model for churn
churn_fit2 <- survfit(Surv(df_churn$Duration, df_churn$Retention) ~ 1, data = df_churn)

#Review results
summary(churn_fit2)
ggsurvplot(fit = churn_fit2, data = df_churn)

```

##QUESTION 3:  CHURN MODEL COMPARISON
=======

Compare Models:
```{r}

```

##QUESTION 4:  ACQUISTION MODEL V. CHURN MODEL COMPARISON
=======

Compare Models:
```{r}

```
