---
title: "Predicting Customer Churn"
name: "Curtis Hampton"
date: "March 29th, 2017"
output: html_notebook
---

```{r}
library(caret)
library(ggplot2)
```

```{r}
# load data
act_activity <- read.csv("account_activity.csv")
cust_info <- read.csv("customer_info.csv")
new_cust <- read.csv("new_customers.csv")
```

# Inspect Data
Make sure that variables are formatted as they should be, and if not, adjust variable type accordingly. 

```{r}
# inspect data stucture
str(act_activity)
```

```{r}
# inspect data stucture
str(cust_info)
```

```{r}
# inspect data stucture
str(new_cust)
```

```{r}
# fix variable types where necessary
cust_info$Churn <- as.factor(cust_info$Churn)
levels(cust_info$Churn) <- make.names(c("no", "yes"))
cust_info$State <- as.factor(cust_info$State)
cust_info$Area_Code <- as.factor(cust_info$Area_Code)
```

```{r}
# count the number of rows
nrow(act_activity)
```

```{r}
# count the number of rows
nrow(cust_info)
```

```{r}
# count the number of rows
nrow(new_cust)
```

# Remove Duplicates

```{r}
# remove complete case duplicates
act_activity <- unique(act_activity)
cust_info <- unique(cust_info)
new_cust <- unique(new_cust)
```

After removing duplicates, count the number of rows again

```{r}
# count the number of rows
nrow(act_activity)
```

```{r}
# count the number of rows
nrow(cust_info)
```

```{r}
# count the number of rows
nrow(new_cust)
```

# Feature Engineering
In the existing dataset, there is no variable for the total number of calls made per customer.  Create a new variable the sums the number of day calls, evening calls, and night calls. 

```{r}
# create total_calls cariables
act_activity$Total_Calls <- act_activity$Day_Calls + act_activity$Eve_Calls + act_activity$Night_Calls
```

# Merge Datasets
To include both account activity and customer information in the dataset used for predicting customer churn, we can join the datasets based on Customer ID. 

```{r}
# merge account activity with customer information
df <- merge(act_activity, cust_info, by="Customer.ID")
```

# Partition Data
Before running a model, we will split the dataset into a training dataset and a test dataset. The training dataset will be used to build the model, and the test dataset will be used to evaluate the model. 

```{r}
# create partition
set.seed(1234)
trainIndex <- createDataPartition(df$Churn, 
                                  p = .7, 
                                  list = FALSE, 
                                  times = 1)

# put data into training and test
train_df <- df[ trainIndex,]
test_df  <- df[-trainIndex,]
```

We will inspect the proportion of churned customers in the training and test datasets to make sure they are similiar

```{r}
prop.table(table(train_df$Churn))
```

```{r}
prop.table(table(test_df$Churn))
```

# Fit Model to Training Data

```{r}
# set up control for cross-validation
ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 5,
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary)
```

```{r}
# run bagged classification model using the training data
set.seed(1234)
tree_fit <- train(Churn ~ . -Customer.ID -Phone,
                  data = train_df,
                  method = "treebag",
                  nbagg = 50,
                  metric = "ROC",
                  preProc = c("center", "scale"),
                  trControl = ctrl)
```

```{r}
# show the results of the model
tree_fit
```

```{r}
# fit model to training data
tree_train <- predict(tree_fit, newdata = train_df, type = "prob")
```

```{r}
# set cut-off value for churn
tree_train$pred <- factor(ifelse(tree_train$yes >= 0.45, "yes", "no"))
tree_train <- cbind(tree_train, actual = train_df$Churn)
```

```{r}
# review performance of model on training data
confusionMatrix(data = tree_train$pred, reference = tree_train$actual, positive = 'yes')
```

```{r}
# plot the posterior probability vs actual
ggplot(data = tree_train) +
  geom_point(mapping = aes(x = yes, y = actual, color = pred), position = position_jitter(w = 0, h = 0.25)) +
  ggtitle("Predicted Probability of Churn vs. Actual Churn Status") + 
  theme(plot.title = element_text(lineheight=.8, face="bold", hjust = 0.5), ) +
  labs(x = "Predicted Probability of Churn", y = "Actual Churn Status") +
  theme(legend.title = element_text(face="bold"), legend.position = "right") +
  scale_color_manual(name = "Predicted Status", values = c("#999999", "#CC0000"))
```

# Fit Model to Test Data

```{r}
# fit model to test data
tree_test <- predict(tree_fit, newdata = test_df, type = "prob")
```

```{r}
# set cut-off value for churn
tree_test$pred <- factor(ifelse(tree_test$yes >= .45, "yes", "no"))
tree_test <- cbind(tree_test, actual = test_df$Churn)
```

```{r}
# review performance of model on test data
confusionMatrix(data = tree_test$pred, reference = tree_test$actual, positive = 'yes')
```

```{r}
# plot the posterior probability vs actual
ggplot(data = tree_test) +
  geom_point(mapping = aes(x = yes, y = actual, color = pred), position = position_jitter(w = 0, h = 0.25)) +
  ggtitle("Predicted Probability of Churn vs. Actual Churn Status") + 
  theme(plot.title = element_text(lineheight=.8, face="bold", hjust = 0.5), ) +
  labs(x = "Predicted Probability of Churn", y = "Actual Churn Status") +
  theme(legend.title = element_text(face="bold"), legend.position = "right") +
  scale_color_manual(name = "Predicted Status", values = c("#999999", "#CC0000"))
```

# Identify Variable Importance
Variable importance measures the amount of decrease in accuracy of the model when each variable is removed from the model.

```{r}
# plot variable importance
plot(varImp(tree_fit), top=20)
```
