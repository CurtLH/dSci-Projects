{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hanes Brand Predictive Maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will make an attempt to correlate the machine sensor data with the failure data to identify when the machine has failed.  In addition, we will aggregrate the sensor data from a 2-minute interval to a 1-hour interval, as well as create a new indicator variables that signifies if the machine failed within the next hour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import datetime\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will connect to the MySQL database and query the tables directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a connection to the database\n",
    "engine = create_engine('mysql+mysqlconnector://champt9:champt9@130.39.81.34:3306/hanes', echo=False)\n",
    "\n",
    "# query the database for dryer 3 data\n",
    "#dryer3_df = pd.read_sql_query(\"SELECT * FROM dryer3 WHERE Quality = 192\", con=engine)\n",
    "#dryer3_nonpm_df = pd.read_sql_query(\"SELECT * FROM dryer3_nonpm\", con=engine)\n",
    "#dryer3_pm_df = pd.read_sql_query(\"SELECT * FROM dryer3_pm\", con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will also store the data in a .pickle file to be able to refer to it later without needed to be connected to the LSU network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle dataset to work with later\n",
    "#pickle.dump(dryer3_df, open('dryer3.p', 'wb'))\n",
    "#pickle.dump(dryer3_nonpm_df, open('dryer3_nonpm.p', 'wb'))\n",
    "#pickle.dump(dryer3_pm_df, open('dryer3_pm.p', 'wb'))\n",
    "\n",
    "# load pickle file\n",
    "dryer3_df = pickle.load(open('dryer3.p', 'rb'))\n",
    "dryer3_nonpm_df = pickle.load(open('dryer3_nonpm.p', 'rb'))\n",
    "dryer3_pm_df = pickle.load(open('dryer3_pm.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Downtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In order to properly attribute the reason why the machine is not running, we need to identify when the downtime begins, how long the downtime lasts, and when the downtime ends.  Once we have this information, we can use a matching rule to classify which of these downtimes are shift change, preventative maintenace, or failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify when Run changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find when the variable 'Run' changes \n",
    "run_change = dryer3_df['Run'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the amount of time between each sensor reading\n",
    "step_length = dryer3_df['Datetime'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the continuous amount of change at each sensor reading from when the variable Run last changed\n",
    "# thanks for the help at StackExchange #155111\n",
    "since_change = []\n",
    "current_delta = 0\n",
    "for is_change, delta in zip(run_change, step_length):\n",
    "    current_delta = 0 if is_change != 0 else \\\n",
    "        current_delta + delta.total_seconds() / 60.0\n",
    "    since_change.append(current_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add these new variables back into the data frame\n",
    "dryer3_df['Run_Change'] = run_change\n",
    "dryer3_df['Step_Length'] = step_length\n",
    "dryer3_df['Time_Since_Change'] = pd.Series(since_change).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Run</th>\n",
       "      <th>Run_Change</th>\n",
       "      <th>Step_Length</th>\n",
       "      <th>Time_Since_Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 00:02:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:02:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 00:04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:02:00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 00:06:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:02:00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 00:08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:02:00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime  Run  Run_Change  Step_Length  Time_Since_Change\n",
       "0 2015-01-01 00:00:00    1         NaN          NaT                0.0\n",
       "1 2015-01-01 00:02:00    1         0.0     00:02:00                2.0\n",
       "2 2015-01-01 00:04:00    1         0.0     00:02:00                4.0\n",
       "3 2015-01-01 00:06:00    1         0.0     00:02:00                6.0\n",
       "4 2015-01-01 00:08:00    1         0.0     00:02:00                8.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a sample of the data\n",
    "dryer3_df[['Datetime', 'Run', 'Run_Change', 'Step_Length', 'Time_Since_Change']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group readings based on Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert df to a list of dicts\n",
    "dryer3_dict = dryer3_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the ID for the first record equal to 0\n",
    "dryer3_dict[0]['GroupId'] = 0\n",
    "\n",
    "# create an auto-incrementing GroupId that updates with change in Run status\n",
    "for i in range(1, len(dryer3_dict)):\n",
    "    if dryer3_dict[i]['Run'] == dryer3_dict[i-1]['Run']:\n",
    "        dryer3_dict[i]['GroupId'] = dryer3_dict[i-1]['GroupId']\n",
    "    else:\n",
    "        dryer3_dict[i]['GroupId'] = dryer3_dict[i-1]['GroupId'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dict with the keys as Group Id\n",
    "dryer3 = {}\n",
    "for line in dryer3_dict:\n",
    "    dryer3[line['GroupId']] = {'groupId' : line['GroupId'],\n",
    "                               'zEvents' : []}\n",
    "\n",
    "# add sensor reads into the dict based on their GroupId\n",
    "for line in dryer3_dict:\n",
    "    dryer3[line['GroupId']]['zEvents'].append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# enrich dict with min, max, duration\n",
    "for line in dryer3:\n",
    "    dryer3[line]['Run'] = dryer3[line]['zEvents'][0]['Run']\n",
    "    dryer3[line]['startDatetime'] = min([item['Datetime'] for item in dryer3[line]['zEvents']])\n",
    "    dryer3[line]['endDatetime'] = max([item['Datetime'] for item in dryer3[line]['zEvents']])\n",
    "    dryer3[line]['duration'] = (dryer3[line]['endDatetime'] - dryer3[line]['startDatetime']).total_seconds() / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create reduced dict without sensor readings\n",
    "dryer3_reduced = []\n",
    "for line in dryer3:\n",
    "    row = {'GroupId' : dryer3[line]['groupId'], \n",
    "           'Run' : dryer3[line]['Run'],\n",
    "           'endDatetime' : dryer3[line]['endDatetime'],\n",
    "           'startDatetime' : dryer3[line]['startDatetime'],\n",
    "           'duration' : dryer3[line]['duration']}\n",
    "    dryer3_reduced.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GroupId</th>\n",
       "      <th>Run</th>\n",
       "      <th>duration</th>\n",
       "      <th>endDatetime</th>\n",
       "      <th>startDatetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2015-01-01 02:38:00</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01 02:40:00</td>\n",
       "      <td>2015-01-01 02:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>254.0</td>\n",
       "      <td>2015-01-01 06:56:00</td>\n",
       "      <td>2015-01-01 02:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01 06:58:00</td>\n",
       "      <td>2015-01-01 06:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2015-01-01 08:46:00</td>\n",
       "      <td>2015-01-01 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GroupId  Run  duration         endDatetime       startDatetime\n",
       "0        0    1     158.0 2015-01-01 02:38:00 2015-01-01 00:00:00\n",
       "1        1    0       0.0 2015-01-01 02:40:00 2015-01-01 02:40:00\n",
       "2        2    1     254.0 2015-01-01 06:56:00 2015-01-01 02:42:00\n",
       "3        3    0       0.0 2015-01-01 06:58:00 2015-01-01 06:58:00\n",
       "4        4    1     106.0 2015-01-01 08:46:00 2015-01-01 07:00:00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a sample of the data\n",
    "pd.DataFrame(dryer3_reduced).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify downtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of failures: 95\n",
      "Number of failures or maintenance: 12\n"
     ]
    }
   ],
   "source": [
    "# get unique dates for preventative maintenance and failure\n",
    "pm_dates = set([line.date() for line in dryer3_pm_df['Completed'].tolist()])\n",
    "failure_dates = set([line.date() for line in dryer3_nonpm_df['Assigned'].tolist()])\n",
    "\n",
    "# define the start and end times for shift change #1 and shift change #2\n",
    "shift_1_start = datetime.time(7, 30, 0)\n",
    "shift_1_end = datetime.time(9, 30, 0)\n",
    "shift_2_start = datetime.time(19, 30, 0)\n",
    "shift_2_end = datetime.time(21, 30, 0)\n",
    "\n",
    "# iterate through the aggregrated data\n",
    "for line in dryer3_reduced:\n",
    "    \n",
    "    # create variables for easy reference\n",
    "    run = line['Run']\n",
    "    start_date = line['startDatetime'].date()\n",
    "    start_time = line['startDatetime'].time()\n",
    "    end_date = line['endDatetime'].date()\n",
    "    end_time = line['endDatetime'].time()\n",
    "    duration = line['duration']\n",
    "    \n",
    "    # until proven otherwise, set all reasons the machine is down to False\n",
    "    line['shift_change'] = False\n",
    "    line['fail_only'] = False\n",
    "    line['pm_or_fail'] = False\n",
    "    \n",
    "    # look for when the machine is down\n",
    "    if line['Run'] == 0:\n",
    "        \n",
    "        # if the downtime started between the start and end times for shift #1 and lasted less than 120 minutes...\n",
    "        if ((shift_1_start <=  start_time <= shift_1_end) or (shift_2_start <=  start_time <= shift_2_end)) and (0 < duration < 120):\n",
    "            line['shift_change'] = True\n",
    "            \n",
    "        # else if the downtime was not shift change, and was on date that both failure and PM happened...\n",
    "        elif duration > 4 and start_date in failure_dates and end_date in pm_dates:\n",
    "            line['pm_or_fail'] = True\n",
    "        \n",
    "        # else if the downtime was not shift change, and was on a date that only failure happend...\n",
    "        elif duration > 4 and start_date in failure_dates and end_date not in pm_dates:\n",
    "            line['fail_only'] = True\n",
    "            \n",
    "        # otherwise, we cannot attribute downtime\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# print the number of classifications made\n",
    "print(\"Number of failures: {}\".format(len([line for line in dryer3_reduced if line['fail_only'] == True])))\n",
    "print(\"Number of failures or maintenance: {}\".format(len([line for line in dryer3_reduced if line['pm_or_fail'] == True])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load downtime into a df\n",
    "df = pd.DataFrame(dryer3_reduced)\n",
    "\n",
    "# recorder columns\n",
    "col_order = ['GroupId', 'startDatetime', 'endDatetime', 'duration', 'Run', 'shift_change', 'fail_only', 'pm_or_fail']\n",
    "df = df.reindex(columns=col_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GroupId</th>\n",
       "      <th>startDatetime</th>\n",
       "      <th>endDatetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>Run</th>\n",
       "      <th>shift_change</th>\n",
       "      <th>fail_only</th>\n",
       "      <th>pm_or_fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>2015-01-01 02:38:00</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 02:40:00</td>\n",
       "      <td>2015-01-01 02:40:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01 02:42:00</td>\n",
       "      <td>2015-01-01 06:56:00</td>\n",
       "      <td>254.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01 06:58:00</td>\n",
       "      <td>2015-01-01 06:58:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-01-01 07:00:00</td>\n",
       "      <td>2015-01-01 08:46:00</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GroupId       startDatetime         endDatetime  duration  Run  \\\n",
       "0        0 2015-01-01 00:00:00 2015-01-01 02:38:00     158.0    1   \n",
       "1        1 2015-01-01 02:40:00 2015-01-01 02:40:00       0.0    0   \n",
       "2        2 2015-01-01 02:42:00 2015-01-01 06:56:00     254.0    1   \n",
       "3        3 2015-01-01 06:58:00 2015-01-01 06:58:00       0.0    0   \n",
       "4        4 2015-01-01 07:00:00 2015-01-01 08:46:00     106.0    1   \n",
       "\n",
       "  shift_change fail_only pm_or_fail  \n",
       "0        False     False      False  \n",
       "1        False     False      False  \n",
       "2        False     False      False  \n",
       "3        False     False      False  \n",
       "4        False     False      False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a sample of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify failures in sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "# get the start and end datetimes for the identified failures\n",
    "# THIS IS EXCLUDING THE OUTLIER WHERE THE MACHINE WAS DOWN FOR 10 days\n",
    "# THIS IS ALSO EXLCUING TIMES WHEN WE CANNOT MAKE A DISTINCTION BETWEEN PREVENTATIVE MAINTENANCE AND FAILURE\n",
    "failure = df[(df['fail_only'] == True) & (df['duration'] < 14000)]\n",
    "print len(failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to dict\n",
    "failure_dict = failure.to_dict('records')\n",
    "\n",
    "# create a set of tuples with starttime and endtime for faster look ups\n",
    "fail_times = set([(line['startDatetime'], line['endDatetime']) for line in failure_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of failures at 2 minute intervals: 2808\n"
     ]
    }
   ],
   "source": [
    "# look through the dryer3 sensor data, and if the datetime of the reading is in the set of fail times, write fail indicator\n",
    "fail_dates = []\n",
    "for line in dryer3_dict:\n",
    "    for item in fail_times:\n",
    "        if item[0] <= line['Datetime'] <= item[1]:\n",
    "            line['FAILURE'] = 1\n",
    "            fail_dates.append(line['Datetime'])\n",
    "\n",
    "# if it wasn't found as a failure, then code it as a 0\n",
    "for line in dryer3_dict:\n",
    "    if 'FAILURE' not in line.keys():\n",
    "        line['FAILURE'] = 0\n",
    "        \n",
    "# print the number of failures tagged\n",
    "print(\"Number of failures at 2 minute intervals: {}\".format(len(fail_dates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look for at the matchup between failures are classified and actual failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the fist and last sensor data\n",
    "d1 = min([line['Datetime'] for line in dryer3_dict]).date()\n",
    "d2 = max([line['Datetime'] for line in dryer3_dict]).date()\n",
    "\n",
    "# find the differencec between the dates\n",
    "delta = d2 - d1\n",
    "\n",
    "# create a list of every day\n",
    "dates = {}\n",
    "for i in range(delta.days + 1):\n",
    "    dates[(d1 + datetime.timedelta(days=i))] = {'recorded_failure' : [],\n",
    "                                                'identified_failure' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in failure dates\n",
    "fail_record_dates = [line.date() for line in dryer3_nonpm_df['Assigned'].tolist()]\n",
    "\n",
    "# go through the recorded failures and all the dates of the failures to the dict\n",
    "for line in fail_record_dates:\n",
    "    dates[line]['recorded_failure'].append(line)\n",
    "    \n",
    "# go through the failures that we identified and all to dict\n",
    "for line in fail_times:\n",
    "    dates[line[0].date()]['identified_failure'].append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count the number of dates identified\n",
    "for key in dates:\n",
    "    dates[key]['num_recorded_failure'] = len(dates[key]['recorded_failure'])\n",
    "    dates[key]['num_identified_failure'] = len(dates[key]['identified_failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_df = pd.DataFrame(dates).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_df.to_csv(\"dates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identified_failure</th>\n",
       "      <th>num_identified_failure</th>\n",
       "      <th>num_recorded_failure</th>\n",
       "      <th>recorded_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-03</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-04</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>[2015-01-05 09:26:00]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[2015-01-05]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               identified_failure num_identified_failure num_recorded_failure  \\\n",
       "2015-01-01                     []                      0                    0   \n",
       "2015-01-02                     []                      0                    0   \n",
       "2015-01-03                     []                      0                    0   \n",
       "2015-01-04                     []                      0                    0   \n",
       "2015-01-05  [2015-01-05 09:26:00]                      1                    1   \n",
       "\n",
       "           recorded_failure  \n",
       "2015-01-01               []  \n",
       "2015-01-02               []  \n",
       "2015-01-03               []  \n",
       "2015-01-04               []  \n",
       "2015-01-05     [2015-01-05]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregreate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our goal is to identify the indicators that lead up to a failure, we are going to aggregrate our 2-minute sensor readings up to the hour level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter to only include the first failure if a failure happens\n",
    "first_fail = []\n",
    "for line in dryer3_dict:\n",
    "    if line['FAILURE'] == 0:\n",
    "        first_fail.append(line)\n",
    "    elif line['FAILURE'] == 1 and line['Time_Since_Change'] == 0:\n",
    "        first_fail.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset into dataframe\n",
    "data = pd.DataFrame(first_fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    339517\n",
       "1        94\n",
       "Name: FAILURE, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of failures\n",
    "data.FAILURE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new variable the anchors the datetime to the lowest hour...used for grouping next\n",
    "# thanks to StackOverflow #27031169\n",
    "data['Datetime_hour'] = data.Datetime.values.astype('<M8[h]')\n",
    "\n",
    "# drop datetime as it's no longer needed\n",
    "data.drop('Datetime', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group the data by the hour level\n",
    "grouped = data.groupby(by='Datetime_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create function to return ratio\n",
    "def ratio(arr):\n",
    "    return float(arr.sum()) / len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decide which variables to binary and which are continuous\n",
    "binary = ['LintSysAuto', 'LintSysEnable', 'PleviaAuto', 'Run', 'QA']\n",
    "\n",
    "continuous = ['CircFan1', 'CircFan2', 'CircFan3', 'CircFan4', 'CircFan5', 'CircFan6', \n",
    "              'CircFanAct1', 'CircFanAct2', 'CircFanAct3', 'CircfanAct4', 'CircFanAct5', 'CircFanAct6',\n",
    "              'Temp1', 'Temp2', 'Temp3', 'Temp4', 'Temp5', 'Temp6',\n",
    "              'TempSet1', 'TempSet2', 'TempSet3', 'TempSet4', 'TempSet5', 'TempSet6',\n",
    "              'Valve1', 'Valve2', 'Valve3', 'Valve4', 'Valve5', 'Valve6', \n",
    "              'EntrySpeed', 'ExitCnvySpeed', 'FeedConvySpeed', 'FolderSpeed', 'LowerCnvySpeed', 'MiddleCnvySpeed', 'HMISpeed',\n",
    "              'EntryRatio', 'ExitCnvyRatio', 'FeedCnvyRatio', 'FolderRatio', 'LowerCnvyRatio', 'MiddleCnvyRatio', \n",
    "              'ExhaustFan', 'ExhaustFanAct', 'ExhaustFanMan', 'HeatRecAct', 'HeatRecSet', 'PSum', 'Plevia', 'Speed']\n",
    "\n",
    "# combine binary and continuous\n",
    "all_vars = []\n",
    "all_vars.extend(binary)\n",
    "all_vars.extend(continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dict for agg arguments\n",
    "args = {}\n",
    "for var in all_vars:\n",
    "    if var in continuous:\n",
    "        args[var] = {var : {str(var + '_mean') : 'mean',\n",
    "                            str(var + '_std')  : 'std',\n",
    "                            str(var + '_min')  : 'min',\n",
    "                            str(var + '_max')  : 'max'}}\n",
    "    if var in binary:\n",
    "        args[var] = {var : {str(var + '_ratio') : ratio}}\n",
    "        \n",
    "# add failure indicator\n",
    "args['FAILURE'] = {'FAILURE' : {'FAILURE' : 'max'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the arguments on the grouped data\n",
    "results = grouped.agg(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop the MultiIndex\n",
    "results.columns = results.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11315\n",
       "1       87\n",
       "Name: FAILURE, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many failures were identified in this grouped data\n",
    "results['FAILURE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advance Failure Indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to identify indicatorsr of a failure before it happens, we are going to shift the indicator to the hour before the failure happens.  Ideally this timeframe will look significantly different than other times in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# capture when the status of FAILURE changes\n",
    "results['FAIL_CHANGE'] = results['FAILURE'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find datetimes where multiple failures happen in a row and drop\n",
    "results = results.drop(results[(results['FAILURE'] == 1) & (results['FAIL_CHANGE'] != 1.0)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find index values for when the failure happened\n",
    "fail_dt = results[results['FAILURE'] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subtract 2 hours from the same of failure\n",
    "new_fail_dts = set()\n",
    "for dt in fail_dt:\n",
    "    new_fail_dts.add((dt - pd.to_timedelta(1, unit='h'), dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set new indicator variable for upcoming failure\n",
    "results['NEW_FAIL'] = 0\n",
    "for i in results.index:\n",
    "    for dt in new_fail_dts:\n",
    "        if dt[0] <= i <= dt[1]:\n",
    "            results.set_value(i, 'NEW_FAIL', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look for when new_fail changes and only keep first one\n",
    "results['FAIL_1_HOUR'] = results.NEW_FAIL.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find datetimes where multiple new failures happen in a row and keep first\n",
    "results = results.drop(results[(results['NEW_FAIL'] == 1) & (results['FAIL_1_HOUR'] == 0)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop unnesessary columns\n",
    "results.drop([\"FAIL_CHANGE\", \"FAIL_1_HOUR\", \"FAILURE\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename failure indicator\n",
    "results = results.rename(columns={'NEW_FAIL' : 'FAIL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort columns in alphabetic order, with DOWN at the beginning\n",
    "cols = ['FAIL']\n",
    "\n",
    "for i in sorted(results.columns):\n",
    "    if i not in cols:\n",
    "        cols.append(i)\n",
    "        \n",
    "# reorder columns\n",
    "results = results[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAIL</th>\n",
       "      <th>CircFan1_max</th>\n",
       "      <th>CircFan1_mean</th>\n",
       "      <th>CircFan1_min</th>\n",
       "      <th>CircFan1_std</th>\n",
       "      <th>CircFan2_max</th>\n",
       "      <th>CircFan2_mean</th>\n",
       "      <th>CircFan2_min</th>\n",
       "      <th>CircFan2_std</th>\n",
       "      <th>CircFan3_max</th>\n",
       "      <th>...</th>\n",
       "      <th>Valve4_min</th>\n",
       "      <th>Valve4_std</th>\n",
       "      <th>Valve5_max</th>\n",
       "      <th>Valve5_mean</th>\n",
       "      <th>Valve5_min</th>\n",
       "      <th>Valve5_std</th>\n",
       "      <th>Valve6_max</th>\n",
       "      <th>Valve6_mean</th>\n",
       "      <th>Valve6_min</th>\n",
       "      <th>Valve6_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime_hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>0.461133</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>4.944404</td>\n",
       "      <td>100</td>\n",
       "      <td>99.5</td>\n",
       "      <td>91</td>\n",
       "      <td>1.943158</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>1.381736</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>1.695498</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FAIL  CircFan1_max  CircFan1_mean  CircFan1_min  \\\n",
       "Datetime_hour                                                          \n",
       "2015-01-01 00:00:00     0           100          100.0           100   \n",
       "2015-01-01 01:00:00     0           100          100.0           100   \n",
       "2015-01-01 02:00:00     0           100          100.0           100   \n",
       "2015-01-01 03:00:00     0           100          100.0           100   \n",
       "2015-01-01 04:00:00     0           100          100.0           100   \n",
       "\n",
       "                     CircFan1_std  CircFan2_max  CircFan2_mean  CircFan2_min  \\\n",
       "Datetime_hour                                                                  \n",
       "2015-01-01 00:00:00           0.0           100          100.0           100   \n",
       "2015-01-01 01:00:00           0.0           100          100.0           100   \n",
       "2015-01-01 02:00:00           0.0           100          100.0           100   \n",
       "2015-01-01 03:00:00           0.0           100          100.0           100   \n",
       "2015-01-01 04:00:00           0.0           100          100.0           100   \n",
       "\n",
       "                     CircFan2_std  CircFan3_max     ...      Valve4_min  \\\n",
       "Datetime_hour                                       ...                   \n",
       "2015-01-01 00:00:00           0.0           100     ...             100   \n",
       "2015-01-01 01:00:00           0.0           100     ...              98   \n",
       "2015-01-01 02:00:00           0.0           100     ...              81   \n",
       "2015-01-01 03:00:00           0.0           100     ...              94   \n",
       "2015-01-01 04:00:00           0.0           100     ...              92   \n",
       "\n",
       "                     Valve4_std  Valve5_max  Valve5_mean  Valve5_min  \\\n",
       "Datetime_hour                                                          \n",
       "2015-01-01 00:00:00    0.000000         100        100.0         100   \n",
       "2015-01-01 01:00:00    0.461133         100        100.0         100   \n",
       "2015-01-01 02:00:00    4.944404         100         99.5          91   \n",
       "2015-01-01 03:00:00    1.381736         100        100.0         100   \n",
       "2015-01-01 04:00:00    1.695498         100        100.0         100   \n",
       "\n",
       "                     Valve5_std  Valve6_max  Valve6_mean  Valve6_min  \\\n",
       "Datetime_hour                                                          \n",
       "2015-01-01 00:00:00    0.000000         100        100.0         100   \n",
       "2015-01-01 01:00:00    0.000000         100        100.0         100   \n",
       "2015-01-01 02:00:00    1.943158         100        100.0         100   \n",
       "2015-01-01 03:00:00    0.000000         100        100.0         100   \n",
       "2015-01-01 04:00:00    0.000000         100        100.0         100   \n",
       "\n",
       "                     Valve6_std  \n",
       "Datetime_hour                    \n",
       "2015-01-01 00:00:00         0.0  \n",
       "2015-01-01 01:00:00         0.0  \n",
       "2015-01-01 02:00:00         0.0  \n",
       "2015-01-01 03:00:00         0.0  \n",
       "2015-01-01 04:00:00         0.0  \n",
       "\n",
       "[5 rows x 210 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a sample of the data\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write new df to SQL\n",
    "results.to_sql(\"dryer3_1_hour_before_fail\", con=engine, index=True, if_exists=\"replace\", chunksize=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
