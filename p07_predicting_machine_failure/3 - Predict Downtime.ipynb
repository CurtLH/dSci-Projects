{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hanes Brand Predictive Maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore various methods to handle the imbalance between the number of failures compared to non-failures.  In addition, we will attempt to fit various classification methods to the data in hopes of successsfully predicting a failure before it happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "packages <- c(\"purrr\", \"doMC\", \"RMySQL\", \"lubridate\", \"ggplot2\", \"caret\", \"DMwR\", \"ROSE\", \"e1071\", \"randomForest\", \n",
    "              \"party\", \"Matrix\", \"xgboost\", \"DiagrammeR\", \"ipred\", \"nnet\", \"pROC\")\n",
    "purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)\n",
    "\n",
    "# set default plot size\n",
    "options(repr.plot.width=10, repr.plot.height=6)\n",
    "\n",
    "# configure multicore processing\n",
    "registerDoMC(cores=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create an open connection to the database\n",
    "#cn <- dbConnect(drv = RMySQL::MySQL(),\n",
    "#                host = \"130.39.81.34\",\n",
    "#                port = 3306,\n",
    "#                user = \"champt9\",\n",
    "#                password = \"champt9\",\n",
    "#                dbname = \"hanes\")\n",
    "\n",
    "# query the database and store the results into a DataFrame\n",
    "#df <- dbGetQuery(cn, \"SELECT * FROM dryer3_1_hour_before_down\")\n",
    "#dbDisconnect(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save df to local machine\n",
    "#saveRDS(df, \"dryer3_1_hour_before_down.Rda\")\n",
    "df <- readRDS(\"dryer3_1_hour_before_down.Rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Datetime_hour</th><th scope=col>DOWN</th><th scope=col>CircFan1_max</th><th scope=col>CircFan1_mean</th><th scope=col>CircFan1_min</th><th scope=col>CircFan1_std</th><th scope=col>CircFan2_max</th><th scope=col>CircFan2_mean</th><th scope=col>CircFan2_min</th><th scope=col>CircFan2_std</th><th scope=col>⋯</th><th scope=col>Valve4_min</th><th scope=col>Valve4_std</th><th scope=col>Valve5_max</th><th scope=col>Valve5_mean</th><th scope=col>Valve5_min</th><th scope=col>Valve5_std</th><th scope=col>Valve6_max</th><th scope=col>Valve6_mean</th><th scope=col>Valve6_min</th><th scope=col>Valve6_std</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2015-01-01 00:00:00</td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>⋯                  </td><td>100                </td><td>0.000000           </td><td>100                </td><td>100.0              </td><td>100                </td><td>0.000000           </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td></tr>\n",
       "\t<tr><td>2015-01-01 01:00:00</td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>⋯                  </td><td> 98                </td><td>0.461133           </td><td>100                </td><td>100.0              </td><td>100                </td><td>0.000000           </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td></tr>\n",
       "\t<tr><td>2015-01-01 02:00:00</td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>⋯                  </td><td> 81                </td><td>4.944404           </td><td>100                </td><td> 99.5              </td><td> 91                </td><td>1.943158           </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td></tr>\n",
       "\t<tr><td>2015-01-01 03:00:00</td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>⋯                  </td><td> 94                </td><td>1.381736           </td><td>100                </td><td>100.0              </td><td>100                </td><td>0.000000           </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td></tr>\n",
       "\t<tr><td>2015-01-01 04:00:00</td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>⋯                  </td><td> 92                </td><td>1.695498           </td><td>100                </td><td>100.0              </td><td>100                </td><td>0.000000           </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td></tr>\n",
       "\t<tr><td>2015-01-01 05:00:00</td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td><td>⋯                  </td><td>100                </td><td>0.000000           </td><td>100                </td><td>100.0              </td><td>100                </td><td>0.000000           </td><td>100                </td><td>100                </td><td>100                </td><td>0                  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " Datetime\\_hour & DOWN & CircFan1\\_max & CircFan1\\_mean & CircFan1\\_min & CircFan1\\_std & CircFan2\\_max & CircFan2\\_mean & CircFan2\\_min & CircFan2\\_std & ⋯ & Valve4\\_min & Valve4\\_std & Valve5\\_max & Valve5\\_mean & Valve5\\_min & Valve5\\_std & Valve6\\_max & Valve6\\_mean & Valve6\\_min & Valve6\\_std\\\\\n",
       "\\hline\n",
       "\t 2015-01-01 00:00:00 & 0                   & 100                 & 100                 & 100                 & 0                   & 100                 & 100                 & 100                 & 0                   & ⋯                   & 100                 & 0.000000            & 100                 & 100.0               & 100                 & 0.000000            & 100                 & 100                 & 100                 & 0                  \\\\\n",
       "\t 2015-01-01 01:00:00 & 0                   & 100                 & 100                 & 100                 & 0                   & 100                 & 100                 & 100                 & 0                   & ⋯                   &  98                 & 0.461133            & 100                 & 100.0               & 100                 & 0.000000            & 100                 & 100                 & 100                 & 0                  \\\\\n",
       "\t 2015-01-01 02:00:00 & 0                   & 100                 & 100                 & 100                 & 0                   & 100                 & 100                 & 100                 & 0                   & ⋯                   &  81                 & 4.944404            & 100                 &  99.5               &  91                 & 1.943158            & 100                 & 100                 & 100                 & 0                  \\\\\n",
       "\t 2015-01-01 03:00:00 & 0                   & 100                 & 100                 & 100                 & 0                   & 100                 & 100                 & 100                 & 0                   & ⋯                   &  94                 & 1.381736            & 100                 & 100.0               & 100                 & 0.000000            & 100                 & 100                 & 100                 & 0                  \\\\\n",
       "\t 2015-01-01 04:00:00 & 0                   & 100                 & 100                 & 100                 & 0                   & 100                 & 100                 & 100                 & 0                   & ⋯                   &  92                 & 1.695498            & 100                 & 100.0               & 100                 & 0.000000            & 100                 & 100                 & 100                 & 0                  \\\\\n",
       "\t 2015-01-01 05:00:00 & 0                   & 100                 & 100                 & 100                 & 0                   & 100                 & 100                 & 100                 & 0                   & ⋯                   & 100                 & 0.000000            & 100                 & 100.0               & 100                 & 0.000000            & 100                 & 100                 & 100                 & 0                  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Datetime_hour | DOWN | CircFan1_max | CircFan1_mean | CircFan1_min | CircFan1_std | CircFan2_max | CircFan2_mean | CircFan2_min | CircFan2_std | ⋯ | Valve4_min | Valve4_std | Valve5_max | Valve5_mean | Valve5_min | Valve5_std | Valve6_max | Valve6_mean | Valve6_min | Valve6_std | \n",
       "|---|---|---|---|---|---|\n",
       "| 2015-01-01 00:00:00 | 0                   | 100                 | 100                 | 100                 | 0                   | 100                 | 100                 | 100                 | 0                   | ⋯                   | 100                 | 0.000000            | 100                 | 100.0               | 100                 | 0.000000            | 100                 | 100                 | 100                 | 0                   | \n",
       "| 2015-01-01 01:00:00 | 0                   | 100                 | 100                 | 100                 | 0                   | 100                 | 100                 | 100                 | 0                   | ⋯                   |  98                 | 0.461133            | 100                 | 100.0               | 100                 | 0.000000            | 100                 | 100                 | 100                 | 0                   | \n",
       "| 2015-01-01 02:00:00 | 0                   | 100                 | 100                 | 100                 | 0                   | 100                 | 100                 | 100                 | 0                   | ⋯                   |  81                 | 4.944404            | 100                 |  99.5               |  91                 | 1.943158            | 100                 | 100                 | 100                 | 0                   | \n",
       "| 2015-01-01 03:00:00 | 0                   | 100                 | 100                 | 100                 | 0                   | 100                 | 100                 | 100                 | 0                   | ⋯                   |  94                 | 1.381736            | 100                 | 100.0               | 100                 | 0.000000            | 100                 | 100                 | 100                 | 0                   | \n",
       "| 2015-01-01 04:00:00 | 0                   | 100                 | 100                 | 100                 | 0                   | 100                 | 100                 | 100                 | 0                   | ⋯                   |  92                 | 1.695498            | 100                 | 100.0               | 100                 | 0.000000            | 100                 | 100                 | 100                 | 0                   | \n",
       "| 2015-01-01 05:00:00 | 0                   | 100                 | 100                 | 100                 | 0                   | 100                 | 100                 | 100                 | 0                   | ⋯                   | 100                 | 0.000000            | 100                 | 100.0               | 100                 | 0.000000            | 100                 | 100                 | 100                 | 0                   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Datetime_hour       DOWN CircFan1_max CircFan1_mean CircFan1_min CircFan1_std\n",
       "1 2015-01-01 00:00:00 0    100          100           100          0           \n",
       "2 2015-01-01 01:00:00 0    100          100           100          0           \n",
       "3 2015-01-01 02:00:00 0    100          100           100          0           \n",
       "4 2015-01-01 03:00:00 0    100          100           100          0           \n",
       "5 2015-01-01 04:00:00 0    100          100           100          0           \n",
       "6 2015-01-01 05:00:00 0    100          100           100          0           \n",
       "  CircFan2_max CircFan2_mean CircFan2_min CircFan2_std ⋯ Valve4_min Valve4_std\n",
       "1 100          100           100          0            ⋯ 100        0.000000  \n",
       "2 100          100           100          0            ⋯  98        0.461133  \n",
       "3 100          100           100          0            ⋯  81        4.944404  \n",
       "4 100          100           100          0            ⋯  94        1.381736  \n",
       "5 100          100           100          0            ⋯  92        1.695498  \n",
       "6 100          100           100          0            ⋯ 100        0.000000  \n",
       "  Valve5_max Valve5_mean Valve5_min Valve5_std Valve6_max Valve6_mean\n",
       "1 100        100.0       100        0.000000   100        100        \n",
       "2 100        100.0       100        0.000000   100        100        \n",
       "3 100         99.5        91        1.943158   100        100        \n",
       "4 100        100.0       100        0.000000   100        100        \n",
       "5 100        100.0       100        0.000000   100        100        \n",
       "6 100        100.0       100        0.000000   100        100        \n",
       "  Valve6_min Valve6_std\n",
       "1 100        0         \n",
       "2 100        0         \n",
       "3 100        0         \n",
       "4 100        0         \n",
       "5 100        0         \n",
       "6 100        0         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a sample of the data\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning, and is both difficult and expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new variable that indicates failure in the next hour\n",
    "df$Class  <- as.factor(df$DOWN)\n",
    "\n",
    "# drop the old failure indicators\n",
    "df$DOWN <- NULL\n",
    "\n",
    "# create variable names for the Class variable\n",
    "levels(df$Class) <- make.names(c(\"notDown\", \"down\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new variables for dates and time\n",
    "df$Datetime_hour <- ymd_hms(df$Datetime)\n",
    "df$Year <- year(df$Datetime_hour)\n",
    "df$Month <- month(df$Datetime_hour)\n",
    "df$Day <- day(df$Datetime_hour)\n",
    "df$Hour <- hour(df$Datetime_hour)\n",
    "df$Minute <- minute(df$Datetime_hour)\n",
    "df$Datetime_hour <- NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Proportion of Downtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we get into looking at the class imbalance, let's look at what months we have data from.  We will also look at how many downtimes happened in each of those months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events per month:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      \n",
       "         1   2   3   4   5   6   7   8   9  10  11  12\n",
       "  2015 701 409 713 697 671 641 687 672 603 501 560 465\n",
       "  2016 419 272 507 611 613 544   0   0   0   0   0   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of downtimes per month:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      \n",
       "        1  2  3  4  5  6  7  8  9 10 11 12\n",
       "  2015 24 11 24 16 24 28 25 27 25 18 29 29\n",
       "  2016 21  9 26 24 17 19  0  0  0  0  0  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the number of records per month\n",
    "cat(\"Number of events per month:\")\n",
    "table(df$Year, df$Month)\n",
    "\n",
    "# look at the number of failures per month\n",
    "cat(\"\\nNumber of downtimes per month:\")\n",
    "down <- df[df$Class == 'down', ]\n",
    "table(down$Year, down$Month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see in the number of downtimes per month is relatively consistent.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of downtimes per month:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         \n",
       "            1   2   3   4   5   6   7   8   9  10  11  12\n",
       "  notDown 677 398 689 681 647 613 662 645 578 483 531 436\n",
       "  down     24  11  24  16  24  28  25  27  25  18  29  29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# subset df to only 2015\n",
    "df <- df[df$Year == 2015, ]\n",
    "\n",
    "# look at the number of failures per month\n",
    "cat(\"Number of downtimes per month:\")\n",
    "table(df$Class, df$Month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In addition, we will also look for and remove variables that remain constant without our newly subsetted dataset.  Variables that remain constant are of no use, as they cannot help us to discriminate a failure from a non-failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables before:"
     ]
    },
    {
     "data": {
      "text/html": [
       "215"
      ],
      "text/latex": [
       "215"
      ],
      "text/markdown": [
       "215"
      ],
      "text/plain": [
       "[1] 215"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of variables after:"
     ]
    },
    {
     "data": {
      "text/html": [
       "169"
      ],
      "text/latex": [
       "169"
      ],
      "text/markdown": [
       "169"
      ],
      "text/plain": [
       "[1] 169"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the number of variables\n",
    "cat(\"Number of variables before:\")\n",
    "ncol(df)\n",
    "\n",
    "# drop variables are are constant\n",
    "df <- df[sapply(df, function(x) length(unique(na.omit(x)))) > 1]\n",
    "    \n",
    "# look at the number of variables\n",
    "cat(\"\\nNumber of variables after:\")\n",
    "ncol(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because this is time-series data, we cannot partition our dataset using a random sample approach.  Instead, we will divide the data by putting the first 9 months into the training data, and the remaining 2 months into the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and test\n",
    "imbal_train <- df[df$Month <= 9, ]\n",
    "imbal_test <- df[df$Month > 9, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downtime ratio in training data:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   notDown       down \n",
       "0.96479116 0.03520884 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downtime ratio in test data:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   notDown       down \n",
       "0.96479116 0.03520884 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare downtime ratio in training and test\n",
    "cat(\"Downtime ratio in training data:\")\n",
    "prop.table(table(imbal_train$Class))\n",
    "\n",
    "cat(\"\\nDowntime ratio in test data:\")\n",
    "prop.table(table(imbal_train$Class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are using 4 different methods in attempt to deal with the imbalanced data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Down Sampling works with majority class. It reduces the number of observations from majority class to make the data set balanced. This method is best to use when the data set is huge and reducing the number of training samples helps to improve run time and storage troubles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of failures to non-failures in the down-sampled dataset:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "notDown    down \n",
       "    204     204 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1234)\n",
    "down_train <- downSample(x = imbal_train[, -ncol(imbal_train)],\n",
    "                         y = imbal_train$Class)\n",
    "\n",
    "cat(\"Number of failures to non-failures in the down-sampled dataset:\")\n",
    "table(down_train$Class)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Up Sampling works with minority class. It replicates the observations from minority class to balance the data. It is also known as upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "notDown    down \n",
       "   5590    5590 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1234)\n",
    "up_train <- upSample(x = imbal_train[, -ncol(imbal_train)],\n",
    "                     y = imbal_train$Class)                         \n",
    "\n",
    "table(up_train$Class) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE (Synthetic Minority Over-sampling Technique) works by creating synthetic samples from the under-represented class instead of creating copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "notDown    down \n",
       "    816     612 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1234)\n",
    "smote_train <- SMOTE(Class ~ ., \n",
    "                     data = imbal_train)                         \n",
    "\n",
    "table(smote_train$Class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROSE (Random Over-Sampling Examples) works by creating synthetic samples from the under-represented class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "notDown    down \n",
       "   2892    2897 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1234)\n",
    "rose_train <- ROSE(Class ~ ., \n",
    "                   data = imbal_train)$data                         \n",
    "\n",
    "table(rose_train$Class) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Balancing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to evalaute the usefulness of the 4 different balancing methods, we will be run the same classification methods on each of these new datasets and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl <- trainControl(method = \"repeatedcv\", \n",
    "                     repeats = 5,\n",
    "                     classProbs = TRUE,\n",
    "                     summaryFunction = twoClassSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "orig_fit <- train(Class ~ ., \n",
    "                   data = imbal_train, \n",
    "                   method = \"treebag\",\n",
    "                   nbagg = 50,\n",
    "                   metric = \"ROC\",\n",
    "                   trControl = ctrl,\n",
    "                   na.action=na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "down_fit <- train(Class ~ ., \n",
    "                   data = down_train, \n",
    "                   method = \"treebag\",\n",
    "                   nbagg = 50,\n",
    "                   metric = \"ROC\",\n",
    "                   trControl = ctrl,\n",
    "                   na.action=na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "up_fit <- train(Class ~ ., \n",
    "                data = up_train, \n",
    "                method = \"treebag\",\n",
    "                nbagg = 50,\n",
    "                metric = \"ROC\",\n",
    "                trControl = ctrl,\n",
    "                na.action=na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "smote_fit <- train(Class ~ ., \n",
    "                    data = smote_train, \n",
    "                    method = \"treebag\",\n",
    "                    nbagg = 50,\n",
    "                    metric = \"ROC\",\n",
    "                    trControl = ctrl,\n",
    "                    na.action=na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "rose_fit <- train(Class ~ ., \n",
    "                  data = rose_train, \n",
    "                  method = \"treebag\",\n",
    "                  nbagg = 50,\n",
    "                  metric = \"ROC\",\n",
    "                  trControl = ctrl,\n",
    "                  na.action=na.exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To compare the different balancing methods, we will validate the models with the test data and compare the ROC values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>lower</th><th scope=col>ROC</th><th scope=col>upper</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>original</th><td>0.4073164</td><td>0.4680717</td><td>0.5288270</td></tr>\n",
       "\t<tr><th scope=row>down</th><td>0.4758308</td><td>0.5376180</td><td>0.5994051</td></tr>\n",
       "\t<tr><th scope=row>up</th><td>0.4333575</td><td>0.5001906</td><td>0.5670236</td></tr>\n",
       "\t<tr><th scope=row>SMOTE</th><td>0.4363882</td><td>0.5017604</td><td>0.5671327</td></tr>\n",
       "\t<tr><th scope=row>ROSE</th><td>0.4998647</td><td>0.5010345</td><td>0.5022043</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & lower & ROC & upper\\\\\n",
       "\\hline\n",
       "\toriginal & 0.4073164 & 0.4680717 & 0.5288270\\\\\n",
       "\tdown & 0.4758308 & 0.5376180 & 0.5994051\\\\\n",
       "\tup & 0.4333575 & 0.5001906 & 0.5670236\\\\\n",
       "\tSMOTE & 0.4363882 & 0.5017604 & 0.5671327\\\\\n",
       "\tROSE & 0.4998647 & 0.5010345 & 0.5022043\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | lower | ROC | upper | \n",
       "|---|---|---|---|---|\n",
       "| original | 0.4073164 | 0.4680717 | 0.5288270 | \n",
       "| down | 0.4758308 | 0.5376180 | 0.5994051 | \n",
       "| up | 0.4333575 | 0.5001906 | 0.5670236 | \n",
       "| SMOTE | 0.4363882 | 0.5017604 | 0.5671327 | \n",
       "| ROSE | 0.4998647 | 0.5010345 | 0.5022043 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "         lower     ROC       upper    \n",
       "original 0.4073164 0.4680717 0.5288270\n",
       "down     0.4758308 0.5376180 0.5994051\n",
       "up       0.4333575 0.5001906 0.5670236\n",
       "SMOTE    0.4363882 0.5017604 0.5671327\n",
       "ROSE     0.4998647 0.5010345 0.5022043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "balance_models <- list(original = orig_fit,\n",
    "                       down = down_fit,\n",
    "                       up = up_fit,\n",
    "                       SMOTE = smote_fit,\n",
    "                       ROSE = rose_fit)\n",
    "\n",
    "balance_resampling <- resamples(balance_models)\n",
    "\n",
    "test_roc <- function(model, data) {\n",
    "  library(pROC)\n",
    "  roc_obj <- roc(data$Class, \n",
    "                 predict(model, data, type = \"prob\")[, \"down\"])\n",
    "  ci(roc_obj)\n",
    "  }\n",
    "\n",
    "balance_test <- lapply(balance_models, test_roc, data = imbal_test)\n",
    "balance_test <- lapply(balance_test, as.vector)\n",
    "balance_test <- do.call(\"rbind\", balance_test)\n",
    "colnames(balance_test) <- c(\"lower\", \"ROC\", \"upper\")\n",
    "balance_test <- as.data.frame(balance_test)\n",
    "\n",
    "#summary(balance_resampling, metric = \"ROC\")\n",
    "balance_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Explore Classification Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define contrls for each model\n",
    "fit_ctrl <- trainControl(method = \"repeatedcv\", \n",
    "                         repeats = 5,\n",
    "                         classProbs = TRUE,\n",
    "                         summaryFunction = twoClassSummary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "rpart_fit <- train(Class ~ ., \n",
    "                   data = imbal_train,\n",
    "                   method = \"rpart\",\n",
    "                   metric = \"ROC\",\n",
    "                   trControl = fit_ctrl,\n",
    "                   na.action = na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "5789 samples\n",
       " 168 predictor\n",
       "   2 classes: 'notDown', 'down' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 5211, 5209, 5211, 5210, 5210, 5210, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp            ROC        Sens       Spec       \n",
       "  0.0006157635  0.5446023  0.9929464  0.007904762\n",
       "  0.0008210181  0.5471583  0.9938413  0.007904762\n",
       "  0.0009852217  0.5436086  0.9943425  0.007904762\n",
       "\n",
       "ROC was used to select the optimal model using  the largest value.\n",
       "The final value used for the model was cp = 0.0008210181. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpart_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rpart variable importance\n",
       "\n",
       "  only 20 most important variables shown (out of 168)\n",
       "\n",
       "                    Overall\n",
       "Temp6_mean           100.00\n",
       "Temp5_mean            94.64\n",
       "Valve5_std            93.39\n",
       "Valve5_min            77.24\n",
       "Valve5_mean           70.29\n",
       "CircFanAct6_min       52.72\n",
       "LowerCnvySpeed_min    50.36\n",
       "ExitCnvySpeed_min     50.36\n",
       "MiddleCnvySpeed_min   50.36\n",
       "FolderSpeed_min       50.36\n",
       "MiddleCnvyRatio_std   44.64\n",
       "Temp6_min             30.66\n",
       "Hour                  25.00\n",
       "Temp2_mean            20.56\n",
       "Plevia_max            19.69\n",
       "Plevia_std            18.53\n",
       "FeedCnvyRatio_std     15.03\n",
       "Valve6_max             0.00\n",
       "Temp4_std              0.00\n",
       "LowerCnvySpeed_std     0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show which variables are important in this model\n",
    "varImp(rpart_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rpart_pred <- predict(rpart_fit, imbal_test, type = \"prob\")\n",
    "rpart_pred$pred <- factor(ifelse(rpart_pred$notDown >= .5, \"notDown\", \"down\"))\n",
    "rpart_pred <- cbind(rpart_pred, actual = imbal_test$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in confusionMatrix.default(data = rpart_pred$pred, reference = rpart_pred$actual):\n",
      "“Levels are not in the same order for reference and data. Refactoring data to match.”"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction notDown down\n",
       "   notDown    1450   76\n",
       "   down          0    0\n",
       "                                          \n",
       "               Accuracy : 0.9502          \n",
       "                 95% CI : (0.9381, 0.9606)\n",
       "    No Information Rate : 0.9502          \n",
       "    P-Value [Acc > NIR] : 0.5305          \n",
       "                                          \n",
       "                  Kappa : 0               \n",
       " Mcnemar's Test P-Value : <2e-16          \n",
       "                                          \n",
       "            Sensitivity : 1.0000          \n",
       "            Specificity : 0.0000          \n",
       "         Pos Pred Value : 0.9502          \n",
       "         Neg Pred Value :    NaN          \n",
       "             Prevalence : 0.9502          \n",
       "         Detection Rate : 0.9502          \n",
       "   Detection Prevalence : 1.0000          \n",
       "      Balanced Accuracy : 0.5000          \n",
       "                                          \n",
       "       'Positive' Class : notDown         \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = rpart_pred$pred, reference = rpart_pred$actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl <- trainControl(method = \"repeatedcv\", \n",
    "                     repeats = 5,\n",
    "                     classProbs = TRUE,\n",
    "                     summaryFunction = twoClassSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "treebag_fit <- train(Class ~ ., \n",
    "                     data = imbal_train,\n",
    "                     method = \"treebag\",\n",
    "                     nbagg = 50,\n",
    "                     metric = \"ROC\",\n",
    "                     trControl = ctrl, \n",
    "                     na.action=na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bagged CART \n",
       "\n",
       "5789 samples\n",
       " 168 predictor\n",
       "   2 classes: 'notDown', 'down' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 5211, 5209, 5211, 5210, 5210, 5210, ... \n",
       "Resampling results:\n",
       "\n",
       "  ROC        Sens       Spec       \n",
       "  0.5646364  0.9985317  0.003857143\n",
       "\n",
       " "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "treebag_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treebag variable importance\n",
       "\n",
       "  only 20 most important variables shown (out of 168)\n",
       "\n",
       "                     Overall\n",
       "LowerCnvySpeed_max    100.00\n",
       "LowerCnvySpeed_mean    88.59\n",
       "LowerCnvySpeed_min     71.97\n",
       "LowerCnvySpeed_std     70.18\n",
       "MiddleCnvyRatio_mean   65.86\n",
       "Temp3_mean             63.30\n",
       "MiddleCnvyRatio_min    62.87\n",
       "MiddleCnvyRatio_max    59.65\n",
       "Temp5_mean             56.87\n",
       "Temp6_mean             55.25\n",
       "Temp1_max              51.96\n",
       "Valve4_mean            51.00\n",
       "Temp3_std              48.70\n",
       "Temp3_max              46.74\n",
       "Temp6_max              46.50\n",
       "Temp1_std              45.94\n",
       "Temp1_mean             45.78\n",
       "Temp3_min              45.09\n",
       "Plevia_std             43.96\n",
       "Temp6_min              43.53"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show which variables are important in this model\n",
    "varImp(treebag_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treebag_pred <- predict(treebag_fit, imbal_test, type = \"prob\")\n",
    "treebag_pred$pred <- factor(ifelse(treebag_pred$notDown >= .5, \"notDown\", \"down\"))\n",
    "treebag_pred <- cbind(treebag_pred, actual = imbal_test$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in confusionMatrix.default(data = treebag_pred$pred, reference = treebag_pred$actual):\n",
      "“Levels are not in the same order for reference and data. Refactoring data to match.”"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction notDown down\n",
       "   notDown    1433   75\n",
       "   down         17    1\n",
       "                                          \n",
       "               Accuracy : 0.9397          \n",
       "                 95% CI : (0.9266, 0.9511)\n",
       "    No Information Rate : 0.9502          \n",
       "    P-Value [Acc > NIR] : 0.9711          \n",
       "                                          \n",
       "                  Kappa : 0.0022          \n",
       " Mcnemar's Test P-Value : 2.804e-09       \n",
       "                                          \n",
       "            Sensitivity : 0.98828         \n",
       "            Specificity : 0.01316         \n",
       "         Pos Pred Value : 0.95027         \n",
       "         Neg Pred Value : 0.05556         \n",
       "             Prevalence : 0.95020         \n",
       "         Detection Rate : 0.93906         \n",
       "   Detection Prevalence : 0.98820         \n",
       "      Balanced Accuracy : 0.50072         \n",
       "                                          \n",
       "       'Positive' Class : notDown         \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = treebag_pred$pred, reference = treebag_pred$actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl <- trainControl(method = \"repeatedcv\", \n",
    "                     repeats = 5,\n",
    "                     classProbs = TRUE,\n",
    "                     summaryFunction = twoClassSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "treebag_smote_fit <- train(Class ~ ., \n",
    "                           data = smote_train,\n",
    "                           method = \"treebag\",\n",
    "                           nbagg = 100,\n",
    "                           metric = \"Spec\",\n",
    "                           trControl = ctrl, \n",
    "                           na.action=na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bagged CART \n",
       "\n",
       "1425 samples\n",
       " 168 predictor\n",
       "   2 classes: 'notDown', 'down' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 1282, 1283, 1284, 1283, 1282, 1282, ... \n",
       "Resampling results:\n",
       "\n",
       "  ROC        Sens       Spec     \n",
       "  0.8803384  0.9333695  0.6955902\n",
       "\n",
       " "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "treebag_smote_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treebag variable importance\n",
       "\n",
       "  only 20 most important variables shown (out of 168)\n",
       "\n",
       "                    Overall\n",
       "FeedCnvyRatio_max    100.00\n",
       "FeedCnvyRatio_mean    97.94\n",
       "FeedCnvyRatio_min     97.56\n",
       "Temp6_mean            28.41\n",
       "Temp5_mean            23.91\n",
       "Temp5_max             18.65\n",
       "Temp6_max             18.42\n",
       "Month                 15.33\n",
       "LowerCnvySpeed_max    14.96\n",
       "Temp6_min             14.63\n",
       "LowerCnvySpeed_min    14.02\n",
       "EntryRatio_min        13.85\n",
       "EntryRatio_max        12.67\n",
       "Temp1_std             12.13\n",
       "Temp1_max             11.85\n",
       "Temp1_mean            11.22\n",
       "Temp3_std             10.50\n",
       "LowerCnvySpeed_mean   10.32\n",
       "Temp3_max             10.09\n",
       "LowerCnvySpeed_std    10.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show which variables are important in this model\n",
    "varImp(treebag_smote_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treebag_smote_pred <- predict(treebag_smote_fit, imbal_test, type = \"prob\")\n",
    "treebag_smote_pred$pred <- factor(ifelse(treebag_smote_pred$notDown >= .5, \"notDown\", \"down\"))\n",
    "treebag_smote_pred <- cbind(treebag_smote_pred, actual = imbal_test$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nBCEAAAAA6NT/B7uZZwxFngWEAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title “AUC: 0.51”"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc <- roc(imbal_test$Class, treebag_smote_pred$notDown)\n",
    "plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))\n",
    "abline(h=1,col='blue',lwd=2)\n",
    "abline(h=0,col='red',lwd=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in confusionMatrix.default(data = treebag_smote_pred$pred, reference = treebag_smote_pred$actual):\n",
      "“Levels are not in the same order for reference and data. Refactoring data to match.”"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction notDown down\n",
       "   notDown     678   40\n",
       "   down        772   36\n",
       "                                          \n",
       "               Accuracy : 0.4679          \n",
       "                 95% CI : (0.4426, 0.4933)\n",
       "    No Information Rate : 0.9502          \n",
       "    P-Value [Acc > NIR] : 1               \n",
       "                                          \n",
       "                  Kappa : -0.0106         \n",
       " Mcnemar's Test P-Value : <2e-16          \n",
       "                                          \n",
       "            Sensitivity : 0.46759         \n",
       "            Specificity : 0.47368         \n",
       "         Pos Pred Value : 0.94429         \n",
       "         Neg Pred Value : 0.04455         \n",
       "             Prevalence : 0.95020         \n",
       "         Detection Rate : 0.44430         \n",
       "   Detection Prevalence : 0.47051         \n",
       "      Balanced Accuracy : 0.47064         \n",
       "                                          \n",
       "       'Positive' Class : notDown         \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = treebag_smote_pred$pred, reference = treebag_smote_pred$actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "svm_fit <- train(Class ~ ., \n",
    "                 data = imbal_train, \n",
    "                 method = \"svmRadial\", \n",
    "                 trControl = fit_ctrl, \n",
    "                 preProc = c(\"center\", \"scale\"),\n",
    "                 #tuneLength = 8,\n",
    "                 metric = \"ROC\", \n",
    "                 na.action = na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Support Vector Machines with Radial Basis Function Kernel \n",
       "\n",
       "5789 samples\n",
       " 168 predictor\n",
       "   2 classes: 'notDown', 'down' \n",
       "\n",
       "Pre-processing: centered (168), scaled (168) \n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 5211, 5209, 5211, 5210, 5210, 5210, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  C     ROC        Sens       Spec\n",
       "  0.25  0.5802250  0.9999284  0   \n",
       "  0.50  0.5801383  0.9999284  0   \n",
       "  1.00  0.5801151  0.9998926  0   \n",
       "\n",
       "Tuning parameter 'sigma' was held constant at a value of 0.009239124\n",
       "ROC was used to select the optimal model using  the largest value.\n",
       "The final values used for the model were sigma = 0.009239124 and C = 0.25. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROC curve variable importance\n",
       "\n",
       "  only 20 most important variables shown (out of 168)\n",
       "\n",
       "                    Importance\n",
       "Valve5_mean             100.00\n",
       "Valve3_mean              97.66\n",
       "Valve5_min               97.54\n",
       "Valve4_mean              95.37\n",
       "Valve3_min               94.14\n",
       "Valve2_mean              94.05\n",
       "Valve4_min               93.28\n",
       "Valve2_min               93.07\n",
       "HMISpeed_min             88.38\n",
       "Speed_min                88.05\n",
       "ExitCnvySpeed_min        81.35\n",
       "FolderSpeed_min          81.32\n",
       "FeedConvySpeed_min       80.51\n",
       "LowerCnvySpeed_min       80.41\n",
       "EntrySpeed_min           79.75\n",
       "MiddleCnvySpeed_min      79.61\n",
       "FolderSpeed_mean         74.58\n",
       "ExitCnvySpeed_mean       73.95\n",
       "LowerCnvySpeed_mean      73.60\n",
       "FeedConvySpeed_mean      73.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show which variables are important in this model\n",
    "varImp(svm_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_pred <- predict(svm_fit, imbal_test, type = \"prob\")\n",
    "svm_pred$pred <- factor(ifelse(svm_pred$notDown >= .5, \"notDown\", \"down\"))\n",
    "svm_pred <- cbind(svm_pred, actual = imbal_test$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in confusionMatrix.default(data = svm_pred$pred, reference = svm_pred$actual):\n",
      "“Levels are not in the same order for reference and data. Refactoring data to match.”"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction notDown down\n",
       "   notDown    1450   76\n",
       "   down          0    0\n",
       "                                          \n",
       "               Accuracy : 0.9502          \n",
       "                 95% CI : (0.9381, 0.9606)\n",
       "    No Information Rate : 0.9502          \n",
       "    P-Value [Acc > NIR] : 0.5305          \n",
       "                                          \n",
       "                  Kappa : 0               \n",
       " Mcnemar's Test P-Value : <2e-16          \n",
       "                                          \n",
       "            Sensitivity : 1.0000          \n",
       "            Specificity : 0.0000          \n",
       "         Pos Pred Value : 0.9502          \n",
       "         Neg Pred Value :    NaN          \n",
       "             Prevalence : 0.9502          \n",
       "         Detection Rate : 0.9502          \n",
       "   Detection Prevalence : 1.0000          \n",
       "      Balanced Accuracy : 0.5000          \n",
       "                                          \n",
       "       'Positive' Class : notDown         \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = svm_pred$pred, reference = svm_pred$actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classification Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in train.default(x, y, weights = w, ...):\n",
      "“The metric \"Accuracy\" was not in the result set. ROC will be used instead.”"
     ]
    }
   ],
   "source": [
    "set.seed(1234)\n",
    "ada_fit <- train(Class ~ ., \n",
    "                 data = imbal_train, \n",
    "                 method = \"adaboost\",\n",
    "                 trControl = fit_ctrl, \n",
    "                 na.action = na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_pred <- predict(ada_fit, imbal_test, type = \"prob\")\n",
    "ada_pred$pred <- factor(ifelse(ada_pred$notDown >= .5, \"notDown\", \"down\"))\n",
    "ada_pred <- cbind(ada_pred, actual = imbal_test$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusionMatrix(data = ada_pred$pred, reference = ada_pred$actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "net_fit <- train(Class ~ ., \n",
    "                 data = imbal_train, \n",
    "                 method = \"avNNet\",\n",
    "                 na.action = na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Averaged Neural Network \n",
       "\n",
       "5789 samples\n",
       " 168 predictor\n",
       "   2 classes: 'notDown', 'down' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Bootstrapped (25 reps) \n",
       "Summary of sample sizes: 5789, 5789, 5789, 5789, 5789, 5789, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  size  decay  Accuracy   Kappa\n",
       "  1     0e+00  0.9653251  0    \n",
       "  1     1e-04  0.9653251  0    \n",
       "  1     1e-01  0.9653251  0    \n",
       "  3     0e+00  0.9653251  0    \n",
       "  3     1e-04  0.9653251  0    \n",
       "  3     1e-01  0.9653251  0    \n",
       "  5     0e+00  0.9653251  0    \n",
       "  5     1e-04  0.9653251  0    \n",
       "  5     1e-01  0.9653251  0    \n",
       "\n",
       "Tuning parameter 'bag' was held constant at a value of FALSE\n",
       "Accuracy was used to select the optimal model using  the largest value.\n",
       "The final values used for the model were size = 1, decay = 0.1 and bag = FALSE. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROC curve variable importance\n",
       "\n",
       "  only 20 most important variables shown (out of 168)\n",
       "\n",
       "                    Importance\n",
       "Valve5_mean             100.00\n",
       "Valve3_mean              97.66\n",
       "Valve5_min               97.54\n",
       "Valve4_mean              95.37\n",
       "Valve3_min               94.14\n",
       "Valve2_mean              94.05\n",
       "Valve4_min               93.28\n",
       "Valve2_min               93.07\n",
       "HMISpeed_min             88.38\n",
       "Speed_min                88.05\n",
       "ExitCnvySpeed_min        81.35\n",
       "FolderSpeed_min          81.32\n",
       "FeedConvySpeed_min       80.51\n",
       "LowerCnvySpeed_min       80.41\n",
       "EntrySpeed_min           79.75\n",
       "MiddleCnvySpeed_min      79.61\n",
       "FolderSpeed_mean         74.58\n",
       "ExitCnvySpeed_mean       73.95\n",
       "LowerCnvySpeed_mean      73.60\n",
       "FeedConvySpeed_mean      73.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show which variables are important in this model\n",
    "varImp(net_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_pred <- predict(net_fit, imbal_test, type = \"prob\")\n",
    "net_pred$pred <- factor(ifelse(net_pred$notDown >= .5, \"notDown\", \"down\"))\n",
    "net_pred <- cbind(net_pred, actual = imbal_test$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in confusionMatrix.default(data = net_pred$pred, reference = net_pred$actual):\n",
      "“Levels are not in the same order for reference and data. Refactoring data to match.”"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction notDown down\n",
       "   notDown    1450   76\n",
       "   down          0    0\n",
       "                                          \n",
       "               Accuracy : 0.9502          \n",
       "                 95% CI : (0.9381, 0.9606)\n",
       "    No Information Rate : 0.9502          \n",
       "    P-Value [Acc > NIR] : 0.5305          \n",
       "                                          \n",
       "                  Kappa : 0               \n",
       " Mcnemar's Test P-Value : <2e-16          \n",
       "                                          \n",
       "            Sensitivity : 1.0000          \n",
       "            Specificity : 0.0000          \n",
       "         Pos Pred Value : 0.9502          \n",
       "         Neg Pred Value :    NaN          \n",
       "             Prevalence : 0.9502          \n",
       "         Detection Rate : 0.9502          \n",
       "   Detection Prevalence : 1.0000          \n",
       "      Balanced Accuracy : 0.5000          \n",
       "                                          \n",
       "       'Positive' Class : notDown         \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = net_pred$pred, reference = net_pred$actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Sensitive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats <- function (data, lev = NULL, model = NULL)  {\n",
    "  c(postResample(data[, \"pred\"], data[, \"obs\"]),\n",
    "    Sens = sensitivity(data[, \"pred\"], data[, \"obs\"]),\n",
    "    Spec = specificity(data[, \"pred\"], data[, \"obs\"]))\n",
    "}\n",
    "\n",
    "ctrl <- trainControl(method = \"repeatedcv\", \n",
    "                     repeats = 5,\n",
    "                     summaryFunction = stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "c50_fit <- train(Class ~ ., \n",
    "                 data = imbal_train, \n",
    "                 method = \"C5.0Cost\",\n",
    "                 tuneGrid = expand.grid(model = \"tree\", \n",
    "                                        winnow = c(TRUE, FALSE),\n",
    "                                        trials = c(1:10),\n",
    "                                        cost = 1:10),\n",
    "                 metric = \"Kappa\",\n",
    "                 trControl = ctrl, \n",
    "                 na.action = na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cost-Sensitive C5.0 \n",
       "\n",
       "5789 samples\n",
       " 168 predictor\n",
       "   2 classes: 'notDown', 'down' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 5 times) \n",
       "Summary of sample sizes: 5211, 5209, 5211, 5210, 5210, 5210, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  winnow  cost  trials  Accuracy  Kappa  Sens  Spec\n",
       "  FALSE    1     1      0.964934  0      1     0   \n",
       "  FALSE    1     2      0.964934  0      1     0   \n",
       "  FALSE    1     3      0.964934  0      1     0   \n",
       "  FALSE    1     4      0.964934  0      1     0   \n",
       "  FALSE    1     5      0.964934  0      1     0   \n",
       "  FALSE    1     6      0.964934  0      1     0   \n",
       "  FALSE    1     7      0.964934  0      1     0   \n",
       "  FALSE    1     8      0.964934  0      1     0   \n",
       "  FALSE    1     9      0.964934  0      1     0   \n",
       "  FALSE    1    10      0.964934  0      1     0   \n",
       "  FALSE    2     1      0.964934  0      1     0   \n",
       "  FALSE    2     2      0.964934  0      1     0   \n",
       "  FALSE    2     3      0.964934  0      1     0   \n",
       "  FALSE    2     4      0.964934  0      1     0   \n",
       "  FALSE    2     5      0.964934  0      1     0   \n",
       "  FALSE    2     6      0.964934  0      1     0   \n",
       "  FALSE    2     7      0.964934  0      1     0   \n",
       "  FALSE    2     8      0.964934  0      1     0   \n",
       "  FALSE    2     9      0.964934  0      1     0   \n",
       "  FALSE    2    10      0.964934  0      1     0   \n",
       "  FALSE    3     1      0.964934  0      1     0   \n",
       "  FALSE    3     2      0.964934  0      1     0   \n",
       "  FALSE    3     3      0.964934  0      1     0   \n",
       "  FALSE    3     4      0.964934  0      1     0   \n",
       "  FALSE    3     5      0.964934  0      1     0   \n",
       "  FALSE    3     6      0.964934  0      1     0   \n",
       "  FALSE    3     7      0.964934  0      1     0   \n",
       "  FALSE    3     8      0.964934  0      1     0   \n",
       "  FALSE    3     9      0.964934  0      1     0   \n",
       "  FALSE    3    10      0.964934  0      1     0   \n",
       "  FALSE    4     1      0.964934  0      1     0   \n",
       "  FALSE    4     2      0.964934  0      1     0   \n",
       "  FALSE    4     3      0.964934  0      1     0   \n",
       "  FALSE    4     4      0.964934  0      1     0   \n",
       "  FALSE    4     5      0.964934  0      1     0   \n",
       "  FALSE    4     6      0.964934  0      1     0   \n",
       "  FALSE    4     7      0.964934  0      1     0   \n",
       "  FALSE    4     8      0.964934  0      1     0   \n",
       "  FALSE    4     9      0.964934  0      1     0   \n",
       "  FALSE    4    10      0.964934  0      1     0   \n",
       "  FALSE    5     1      0.964934  0      1     0   \n",
       "  FALSE    5     2      0.964934  0      1     0   \n",
       "  FALSE    5     3      0.964934  0      1     0   \n",
       "  FALSE    5     4      0.964934  0      1     0   \n",
       "  FALSE    5     5      0.964934  0      1     0   \n",
       "  FALSE    5     6      0.964934  0      1     0   \n",
       "  FALSE    5     7      0.964934  0      1     0   \n",
       "  FALSE    5     8      0.964934  0      1     0   \n",
       "  FALSE    5     9      0.964934  0      1     0   \n",
       "  FALSE    5    10      0.964934  0      1     0   \n",
       "  FALSE    6     1      0.964934  0      1     0   \n",
       "  FALSE    6     2      0.964934  0      1     0   \n",
       "  FALSE    6     3      0.964934  0      1     0   \n",
       "  FALSE    6     4      0.964934  0      1     0   \n",
       "  FALSE    6     5      0.964934  0      1     0   \n",
       "  FALSE    6     6      0.964934  0      1     0   \n",
       "  FALSE    6     7      0.964934  0      1     0   \n",
       "  FALSE    6     8      0.964934  0      1     0   \n",
       "  FALSE    6     9      0.964934  0      1     0   \n",
       "  FALSE    6    10      0.964934  0      1     0   \n",
       "  FALSE    7     1      0.964934  0      1     0   \n",
       "  FALSE    7     2      0.964934  0      1     0   \n",
       "  FALSE    7     3      0.964934  0      1     0   \n",
       "  FALSE    7     4      0.964934  0      1     0   \n",
       "  FALSE    7     5      0.964934  0      1     0   \n",
       "  FALSE    7     6      0.964934  0      1     0   \n",
       "  FALSE    7     7      0.964934  0      1     0   \n",
       "  FALSE    7     8      0.964934  0      1     0   \n",
       "  FALSE    7     9      0.964934  0      1     0   \n",
       "  FALSE    7    10      0.964934  0      1     0   \n",
       "  FALSE    8     1      0.964934  0      1     0   \n",
       "  FALSE    8     2      0.964934  0      1     0   \n",
       "  FALSE    8     3      0.964934  0      1     0   \n",
       "  FALSE    8     4      0.964934  0      1     0   \n",
       "  FALSE    8     5      0.964934  0      1     0   \n",
       "  FALSE    8     6      0.964934  0      1     0   \n",
       "  FALSE    8     7      0.964934  0      1     0   \n",
       "  FALSE    8     8      0.964934  0      1     0   \n",
       "  FALSE    8     9      0.964934  0      1     0   \n",
       "  FALSE    8    10      0.964934  0      1     0   \n",
       "  FALSE    9     1      0.964934  0      1     0   \n",
       "  FALSE    9     2      0.964934  0      1     0   \n",
       "  FALSE    9     3      0.964934  0      1     0   \n",
       "  FALSE    9     4      0.964934  0      1     0   \n",
       "  FALSE    9     5      0.964934  0      1     0   \n",
       "  FALSE    9     6      0.964934  0      1     0   \n",
       "  FALSE    9     7      0.964934  0      1     0   \n",
       "  FALSE    9     8      0.964934  0      1     0   \n",
       "  FALSE    9     9      0.964934  0      1     0   \n",
       "  FALSE    9    10      0.964934  0      1     0   \n",
       "  FALSE   10     1      0.964934  0      1     0   \n",
       "  FALSE   10     2      0.964934  0      1     0   \n",
       "  FALSE   10     3      0.964934  0      1     0   \n",
       "  FALSE   10     4      0.964934  0      1     0   \n",
       "  FALSE   10     5      0.964934  0      1     0   \n",
       "  FALSE   10     6      0.964934  0      1     0   \n",
       "  FALSE   10     7      0.964934  0      1     0   \n",
       "  FALSE   10     8      0.964934  0      1     0   \n",
       "  FALSE   10     9      0.964934  0      1     0   \n",
       "  FALSE   10    10      0.964934  0      1     0   \n",
       "   TRUE    1     1      0.964934  0      1     0   \n",
       "   TRUE    1     2      0.964934  0      1     0   \n",
       "   TRUE    1     3      0.964934  0      1     0   \n",
       "   TRUE    1     4      0.964934  0      1     0   \n",
       "   TRUE    1     5      0.964934  0      1     0   \n",
       "   TRUE    1     6      0.964934  0      1     0   \n",
       "   TRUE    1     7      0.964934  0      1     0   \n",
       "   TRUE    1     8      0.964934  0      1     0   \n",
       "   TRUE    1     9      0.964934  0      1     0   \n",
       "   TRUE    1    10      0.964934  0      1     0   \n",
       "   TRUE    2     1      0.964934  0      1     0   \n",
       "   TRUE    2     2      0.964934  0      1     0   \n",
       "   TRUE    2     3      0.964934  0      1     0   \n",
       "   TRUE    2     4      0.964934  0      1     0   \n",
       "   TRUE    2     5      0.964934  0      1     0   \n",
       "   TRUE    2     6      0.964934  0      1     0   \n",
       "   TRUE    2     7      0.964934  0      1     0   \n",
       "   TRUE    2     8      0.964934  0      1     0   \n",
       "   TRUE    2     9      0.964934  0      1     0   \n",
       "   TRUE    2    10      0.964934  0      1     0   \n",
       "   TRUE    3     1      0.964934  0      1     0   \n",
       "   TRUE    3     2      0.964934  0      1     0   \n",
       "   TRUE    3     3      0.964934  0      1     0   \n",
       "   TRUE    3     4      0.964934  0      1     0   \n",
       "   TRUE    3     5      0.964934  0      1     0   \n",
       "   TRUE    3     6      0.964934  0      1     0   \n",
       "   TRUE    3     7      0.964934  0      1     0   \n",
       "   TRUE    3     8      0.964934  0      1     0   \n",
       "   TRUE    3     9      0.964934  0      1     0   \n",
       "   TRUE    3    10      0.964934  0      1     0   \n",
       "   TRUE    4     1      0.964934  0      1     0   \n",
       "   TRUE    4     2      0.964934  0      1     0   \n",
       "   TRUE    4     3      0.964934  0      1     0   \n",
       "   TRUE    4     4      0.964934  0      1     0   \n",
       "   TRUE    4     5      0.964934  0      1     0   \n",
       "   TRUE    4     6      0.964934  0      1     0   \n",
       "   TRUE    4     7      0.964934  0      1     0   \n",
       "   TRUE    4     8      0.964934  0      1     0   \n",
       "   TRUE    4     9      0.964934  0      1     0   \n",
       "   TRUE    4    10      0.964934  0      1     0   \n",
       "   TRUE    5     1      0.964934  0      1     0   \n",
       "   TRUE    5     2      0.964934  0      1     0   \n",
       "   TRUE    5     3      0.964934  0      1     0   \n",
       "   TRUE    5     4      0.964934  0      1     0   \n",
       "   TRUE    5     5      0.964934  0      1     0   \n",
       "   TRUE    5     6      0.964934  0      1     0   \n",
       "   TRUE    5     7      0.964934  0      1     0   \n",
       "   TRUE    5     8      0.964934  0      1     0   \n",
       "   TRUE    5     9      0.964934  0      1     0   \n",
       "   TRUE    5    10      0.964934  0      1     0   \n",
       "   TRUE    6     1      0.964934  0      1     0   \n",
       "   TRUE    6     2      0.964934  0      1     0   \n",
       "   TRUE    6     3      0.964934  0      1     0   \n",
       "   TRUE    6     4      0.964934  0      1     0   \n",
       "   TRUE    6     5      0.964934  0      1     0   \n",
       "   TRUE    6     6      0.964934  0      1     0   \n",
       "   TRUE    6     7      0.964934  0      1     0   \n",
       "   TRUE    6     8      0.964934  0      1     0   \n",
       "   TRUE    6     9      0.964934  0      1     0   \n",
       "   TRUE    6    10      0.964934  0      1     0   \n",
       "   TRUE    7     1      0.964934  0      1     0   \n",
       "   TRUE    7     2      0.964934  0      1     0   \n",
       "   TRUE    7     3      0.964934  0      1     0   \n",
       "   TRUE    7     4      0.964934  0      1     0   \n",
       "   TRUE    7     5      0.964934  0      1     0   \n",
       "   TRUE    7     6      0.964934  0      1     0   \n",
       "   TRUE    7     7      0.964934  0      1     0   \n",
       "   TRUE    7     8      0.964934  0      1     0   \n",
       "   TRUE    7     9      0.964934  0      1     0   \n",
       "   TRUE    7    10      0.964934  0      1     0   \n",
       "   TRUE    8     1      0.964934  0      1     0   \n",
       "   TRUE    8     2      0.964934  0      1     0   \n",
       "   TRUE    8     3      0.964934  0      1     0   \n",
       "   TRUE    8     4      0.964934  0      1     0   \n",
       "   TRUE    8     5      0.964934  0      1     0   \n",
       "   TRUE    8     6      0.964934  0      1     0   \n",
       "   TRUE    8     7      0.964934  0      1     0   \n",
       "   TRUE    8     8      0.964934  0      1     0   \n",
       "   TRUE    8     9      0.964934  0      1     0   \n",
       "   TRUE    8    10      0.964934  0      1     0   \n",
       "   TRUE    9     1      0.964934  0      1     0   \n",
       "   TRUE    9     2      0.964934  0      1     0   \n",
       "   TRUE    9     3      0.964934  0      1     0   \n",
       "   TRUE    9     4      0.964934  0      1     0   \n",
       "   TRUE    9     5      0.964934  0      1     0   \n",
       "   TRUE    9     6      0.964934  0      1     0   \n",
       "   TRUE    9     7      0.964934  0      1     0   \n",
       "   TRUE    9     8      0.964934  0      1     0   \n",
       "   TRUE    9     9      0.964934  0      1     0   \n",
       "   TRUE    9    10      0.964934  0      1     0   \n",
       "   TRUE   10     1      0.964934  0      1     0   \n",
       "   TRUE   10     2      0.964934  0      1     0   \n",
       "   TRUE   10     3      0.964934  0      1     0   \n",
       "   TRUE   10     4      0.964934  0      1     0   \n",
       "   TRUE   10     5      0.964934  0      1     0   \n",
       "   TRUE   10     6      0.964934  0      1     0   \n",
       "   TRUE   10     7      0.964934  0      1     0   \n",
       "   TRUE   10     8      0.964934  0      1     0   \n",
       "   TRUE   10     9      0.964934  0      1     0   \n",
       "   TRUE   10    10      0.964934  0      1     0   \n",
       "\n",
       "Tuning parameter 'model' was held constant at a value of tree\n",
       "Kappa was used to select the optimal model using  the largest value.\n",
       "The final values used for the model were trials = 1, model = tree, winnow\n",
       " = TRUE and cost = 1. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c50_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c50_pred <- predict(c50_fit, imbal_test)\n",
    "c50_pred <- data.frame(predicted = c50_pred, actual = imbal_test$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction notDown down\n",
       "   notDown    1450   76\n",
       "   down          0    0\n",
       "                                          \n",
       "               Accuracy : 0.9502          \n",
       "                 95% CI : (0.9381, 0.9606)\n",
       "    No Information Rate : 0.9502          \n",
       "    P-Value [Acc > NIR] : 0.5305          \n",
       "                                          \n",
       "                  Kappa : 0               \n",
       " Mcnemar's Test P-Value : <2e-16          \n",
       "                                          \n",
       "            Sensitivity : 1.0000          \n",
       "            Specificity : 0.0000          \n",
       "         Pos Pred Value : 0.9502          \n",
       "         Neg Pred Value :    NaN          \n",
       "             Prevalence : 0.9502          \n",
       "         Detection Rate : 0.9502          \n",
       "   Detection Prevalence : 1.0000          \n",
       "      Balanced Accuracy : 0.5000          \n",
       "                                          \n",
       "       'Positive' Class : notDown         \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = c50_pred$predicted, reference = c50_pred$actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPART with Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cctrl1 <- trainControl(method = \"cv\", \n",
    "                       number = 3, \n",
    "                       returnResamp = \"all\")\n",
    "\n",
    "cctrl2 <- trainControl(method = \"LOOCV\")\n",
    "\n",
    "cctrl3 <- trainControl(method = \"none\")\n",
    "\n",
    "cctrlR <- trainControl(method = \"cv\", \n",
    "                       number = 3, \n",
    "                       returnResamp = \"all\", \n",
    "                       search = \"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "rpartC_fit <- train(Class ~ ., \n",
    "                    data = imbal_train, \n",
    "                    method = \"rpartCost\", \n",
    "                    trControl = cctrl2,\n",
    "                    preProc = c(\"center\", \"scale\"), \n",
    "                    metric = \"Kappa\",\n",
    "                    na.action = na.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cost-Sensitive CART \n",
       "\n",
       "5789 samples\n",
       " 168 predictor\n",
       "   2 classes: 'notDown', 'down' \n",
       "\n",
       "Pre-processing: centered (168), scaled (168) \n",
       "Resampling: Leave-One-Out Cross-Validation \n",
       "Summary of sample sizes: 5788, 5788, 5788, 5788, 5788, 5788, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp            Cost  Accuracy   Kappa       \n",
       "  0.0006157635  3     0.9649335   0.000000000\n",
       "  0.0008210181  2     0.9644153  -0.001022399\n",
       "  0.0009852217  1     0.9632061   0.022388101\n",
       "\n",
       "Kappa was used to select the optimal model using  the largest value.\n",
       "The final values used for the model were cp = 0.0009852217 and Cost = 1. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpartC_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rpartC_pred <- predict(rpartC_fit, imbal_test)\n",
    "rpartC_pred <- data.frame(predicted = rpartC_pred, actual = imbal_test$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction notDown down\n",
       "   notDown    1450   76\n",
       "   down          0    0\n",
       "                                          \n",
       "               Accuracy : 0.9502          \n",
       "                 95% CI : (0.9381, 0.9606)\n",
       "    No Information Rate : 0.9502          \n",
       "    P-Value [Acc > NIR] : 0.5305          \n",
       "                                          \n",
       "                  Kappa : 0               \n",
       " Mcnemar's Test P-Value : <2e-16          \n",
       "                                          \n",
       "            Sensitivity : 1.0000          \n",
       "            Specificity : 0.0000          \n",
       "         Pos Pred Value : 0.9502          \n",
       "         Neg Pred Value :    NaN          \n",
       "             Prevalence : 0.9502          \n",
       "         Detection Rate : 0.9502          \n",
       "   Detection Prevalence : 1.0000          \n",
       "      Balanced Accuracy : 0.5000          \n",
       "                                          \n",
       "       'Positive' Class : notDown         \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(data = rpartC_pred$predicted, reference = rpartC_pred$actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Overall</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>CircFanAct6_min</th><td> 52.71660</td></tr>\n",
       "\t<tr><th scope=row>ExitCnvySpeed_min</th><td> 50.36131</td></tr>\n",
       "\t<tr><th scope=row>FeedCnvyRatio_std</th><td> 15.02560</td></tr>\n",
       "\t<tr><th scope=row>FolderSpeed_min</th><td> 50.36131</td></tr>\n",
       "\t<tr><th scope=row>Hour</th><td> 25.00330</td></tr>\n",
       "\t<tr><th scope=row>LowerCnvySpeed_min</th><td> 50.36131</td></tr>\n",
       "\t<tr><th scope=row>MiddleCnvyRatio_std</th><td> 44.64438</td></tr>\n",
       "\t<tr><th scope=row>MiddleCnvySpeed_min</th><td> 50.36131</td></tr>\n",
       "\t<tr><th scope=row>Plevia_max</th><td> 19.68849</td></tr>\n",
       "\t<tr><th scope=row>Plevia_std</th><td> 18.52597</td></tr>\n",
       "\t<tr><th scope=row>Temp2_mean</th><td> 20.55728</td></tr>\n",
       "\t<tr><th scope=row>Temp5_mean</th><td> 94.64357</td></tr>\n",
       "\t<tr><th scope=row>Temp6_mean</th><td>100.00000</td></tr>\n",
       "\t<tr><th scope=row>Temp6_min</th><td> 30.65770</td></tr>\n",
       "\t<tr><th scope=row>Valve5_mean</th><td> 70.28879</td></tr>\n",
       "\t<tr><th scope=row>Valve5_min</th><td> 77.23588</td></tr>\n",
       "\t<tr><th scope=row>Valve5_std</th><td> 93.39161</td></tr>\n",
       "\t<tr><th scope=row>MiddleCnvyRatio_min</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>MiddleCnvyRatio_mean</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>MiddleCnvyRatio_max</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>LowerCnvySpeed_max</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>LowerCnvySpeed_std</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>LowerCnvySpeed_mean</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>HeatRecAct_std</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>HeatRecAct_mean</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>HeatRecAct_max</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>HeatRecAct_min</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>CircfanAct4_std</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>CircfanAct4_min</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>CircfanAct4_max</th><td>  0.00000</td></tr>\n",
       "\t<tr><th scope=row>⋮</th><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct5_std</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct5_max</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct5_min</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct5_mean</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct3_mean</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct3_std</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct3_max</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct3_min</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct2_max</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct2_std</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct2_min</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct2_mean</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct1_mean</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct1_std</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct1_max</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>CircFanAct1_min</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Temp4_mean</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Temp4_std</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Temp4_max</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Temp4_min</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Speed_min</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Speed_mean</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Speed_std</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Speed_max</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>PSum_min</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>PSum_max</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>PSum_mean</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>PSum_std</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Month</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>Day</th><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & Overall\\\\\n",
       "\\hline\n",
       "\tCircFanAct6\\_min &  52.71660\\\\\n",
       "\tExitCnvySpeed\\_min &  50.36131\\\\\n",
       "\tFeedCnvyRatio\\_std &  15.02560\\\\\n",
       "\tFolderSpeed\\_min &  50.36131\\\\\n",
       "\tHour &  25.00330\\\\\n",
       "\tLowerCnvySpeed\\_min &  50.36131\\\\\n",
       "\tMiddleCnvyRatio\\_std &  44.64438\\\\\n",
       "\tMiddleCnvySpeed\\_min &  50.36131\\\\\n",
       "\tPlevia\\_max &  19.68849\\\\\n",
       "\tPlevia\\_std &  18.52597\\\\\n",
       "\tTemp2\\_mean &  20.55728\\\\\n",
       "\tTemp5\\_mean &  94.64357\\\\\n",
       "\tTemp6\\_mean & 100.00000\\\\\n",
       "\tTemp6\\_min &  30.65770\\\\\n",
       "\tValve5\\_mean &  70.28879\\\\\n",
       "\tValve5\\_min &  77.23588\\\\\n",
       "\tValve5\\_std &  93.39161\\\\\n",
       "\tMiddleCnvyRatio\\_min &   0.00000\\\\\n",
       "\tMiddleCnvyRatio\\_mean &   0.00000\\\\\n",
       "\tMiddleCnvyRatio\\_max &   0.00000\\\\\n",
       "\tLowerCnvySpeed\\_max &   0.00000\\\\\n",
       "\tLowerCnvySpeed\\_std &   0.00000\\\\\n",
       "\tLowerCnvySpeed\\_mean &   0.00000\\\\\n",
       "\tHeatRecAct\\_std &   0.00000\\\\\n",
       "\tHeatRecAct\\_mean &   0.00000\\\\\n",
       "\tHeatRecAct\\_max &   0.00000\\\\\n",
       "\tHeatRecAct\\_min &   0.00000\\\\\n",
       "\tCircfanAct4\\_std &   0.00000\\\\\n",
       "\tCircfanAct4\\_min &   0.00000\\\\\n",
       "\tCircfanAct4\\_max &   0.00000\\\\\n",
       "\t⋮ & ⋮\\\\\n",
       "\tCircFanAct5\\_std & 0\\\\\n",
       "\tCircFanAct5\\_max & 0\\\\\n",
       "\tCircFanAct5\\_min & 0\\\\\n",
       "\tCircFanAct5\\_mean & 0\\\\\n",
       "\tCircFanAct3\\_mean & 0\\\\\n",
       "\tCircFanAct3\\_std & 0\\\\\n",
       "\tCircFanAct3\\_max & 0\\\\\n",
       "\tCircFanAct3\\_min & 0\\\\\n",
       "\tCircFanAct2\\_max & 0\\\\\n",
       "\tCircFanAct2\\_std & 0\\\\\n",
       "\tCircFanAct2\\_min & 0\\\\\n",
       "\tCircFanAct2\\_mean & 0\\\\\n",
       "\tCircFanAct1\\_mean & 0\\\\\n",
       "\tCircFanAct1\\_std & 0\\\\\n",
       "\tCircFanAct1\\_max & 0\\\\\n",
       "\tCircFanAct1\\_min & 0\\\\\n",
       "\tTemp4\\_mean & 0\\\\\n",
       "\tTemp4\\_std & 0\\\\\n",
       "\tTemp4\\_max & 0\\\\\n",
       "\tTemp4\\_min & 0\\\\\n",
       "\tSpeed\\_min & 0\\\\\n",
       "\tSpeed\\_mean & 0\\\\\n",
       "\tSpeed\\_std & 0\\\\\n",
       "\tSpeed\\_max & 0\\\\\n",
       "\tPSum\\_min & 0\\\\\n",
       "\tPSum\\_max & 0\\\\\n",
       "\tPSum\\_mean & 0\\\\\n",
       "\tPSum\\_std & 0\\\\\n",
       "\tMonth & 0\\\\\n",
       "\tDay & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Overall | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| CircFanAct6_min |  52.71660 | \n",
       "| ExitCnvySpeed_min |  50.36131 | \n",
       "| FeedCnvyRatio_std |  15.02560 | \n",
       "| FolderSpeed_min |  50.36131 | \n",
       "| Hour |  25.00330 | \n",
       "| LowerCnvySpeed_min |  50.36131 | \n",
       "| MiddleCnvyRatio_std |  44.64438 | \n",
       "| MiddleCnvySpeed_min |  50.36131 | \n",
       "| Plevia_max |  19.68849 | \n",
       "| Plevia_std |  18.52597 | \n",
       "| Temp2_mean |  20.55728 | \n",
       "| Temp5_mean |  94.64357 | \n",
       "| Temp6_mean | 100.00000 | \n",
       "| Temp6_min |  30.65770 | \n",
       "| Valve5_mean |  70.28879 | \n",
       "| Valve5_min |  77.23588 | \n",
       "| Valve5_std |  93.39161 | \n",
       "| MiddleCnvyRatio_min |   0.00000 | \n",
       "| MiddleCnvyRatio_mean |   0.00000 | \n",
       "| MiddleCnvyRatio_max |   0.00000 | \n",
       "| LowerCnvySpeed_max |   0.00000 | \n",
       "| LowerCnvySpeed_std |   0.00000 | \n",
       "| LowerCnvySpeed_mean |   0.00000 | \n",
       "| HeatRecAct_std |   0.00000 | \n",
       "| HeatRecAct_mean |   0.00000 | \n",
       "| HeatRecAct_max |   0.00000 | \n",
       "| HeatRecAct_min |   0.00000 | \n",
       "| CircfanAct4_std |   0.00000 | \n",
       "| CircfanAct4_min |   0.00000 | \n",
       "| CircfanAct4_max |   0.00000 | \n",
       "| ⋮ | ⋮ | \n",
       "| CircFanAct5_std | 0 | \n",
       "| CircFanAct5_max | 0 | \n",
       "| CircFanAct5_min | 0 | \n",
       "| CircFanAct5_mean | 0 | \n",
       "| CircFanAct3_mean | 0 | \n",
       "| CircFanAct3_std | 0 | \n",
       "| CircFanAct3_max | 0 | \n",
       "| CircFanAct3_min | 0 | \n",
       "| CircFanAct2_max | 0 | \n",
       "| CircFanAct2_std | 0 | \n",
       "| CircFanAct2_min | 0 | \n",
       "| CircFanAct2_mean | 0 | \n",
       "| CircFanAct1_mean | 0 | \n",
       "| CircFanAct1_std | 0 | \n",
       "| CircFanAct1_max | 0 | \n",
       "| CircFanAct1_min | 0 | \n",
       "| Temp4_mean | 0 | \n",
       "| Temp4_std | 0 | \n",
       "| Temp4_max | 0 | \n",
       "| Temp4_min | 0 | \n",
       "| Speed_min | 0 | \n",
       "| Speed_mean | 0 | \n",
       "| Speed_std | 0 | \n",
       "| Speed_max | 0 | \n",
       "| PSum_min | 0 | \n",
       "| PSum_max | 0 | \n",
       "| PSum_mean | 0 | \n",
       "| PSum_std | 0 | \n",
       "| Month | 0 | \n",
       "| Day | 0 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                     Overall  \n",
       "CircFanAct6_min       52.71660\n",
       "ExitCnvySpeed_min     50.36131\n",
       "FeedCnvyRatio_std     15.02560\n",
       "FolderSpeed_min       50.36131\n",
       "Hour                  25.00330\n",
       "LowerCnvySpeed_min    50.36131\n",
       "MiddleCnvyRatio_std   44.64438\n",
       "MiddleCnvySpeed_min   50.36131\n",
       "Plevia_max            19.68849\n",
       "Plevia_std            18.52597\n",
       "Temp2_mean            20.55728\n",
       "Temp5_mean            94.64357\n",
       "Temp6_mean           100.00000\n",
       "Temp6_min             30.65770\n",
       "Valve5_mean           70.28879\n",
       "Valve5_min            77.23588\n",
       "Valve5_std            93.39161\n",
       "MiddleCnvyRatio_min    0.00000\n",
       "MiddleCnvyRatio_mean   0.00000\n",
       "MiddleCnvyRatio_max    0.00000\n",
       "LowerCnvySpeed_max     0.00000\n",
       "LowerCnvySpeed_std     0.00000\n",
       "LowerCnvySpeed_mean    0.00000\n",
       "HeatRecAct_std         0.00000\n",
       "HeatRecAct_mean        0.00000\n",
       "HeatRecAct_max         0.00000\n",
       "HeatRecAct_min         0.00000\n",
       "CircfanAct4_std        0.00000\n",
       "CircfanAct4_min        0.00000\n",
       "CircfanAct4_max        0.00000\n",
       "⋮                    ⋮        \n",
       "CircFanAct5_std      0        \n",
       "CircFanAct5_max      0        \n",
       "CircFanAct5_min      0        \n",
       "CircFanAct5_mean     0        \n",
       "CircFanAct3_mean     0        \n",
       "CircFanAct3_std      0        \n",
       "CircFanAct3_max      0        \n",
       "CircFanAct3_min      0        \n",
       "CircFanAct2_max      0        \n",
       "CircFanAct2_std      0        \n",
       "CircFanAct2_min      0        \n",
       "CircFanAct2_mean     0        \n",
       "CircFanAct1_mean     0        \n",
       "CircFanAct1_std      0        \n",
       "CircFanAct1_max      0        \n",
       "CircFanAct1_min      0        \n",
       "Temp4_mean           0        \n",
       "Temp4_std            0        \n",
       "Temp4_max            0        \n",
       "Temp4_min            0        \n",
       "Speed_min            0        \n",
       "Speed_mean           0        \n",
       "Speed_std            0        \n",
       "Speed_max            0        \n",
       "PSum_min             0        \n",
       "PSum_max             0        \n",
       "PSum_mean            0        \n",
       "PSum_std             0        \n",
       "Month                0        \n",
       "Day                  0        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpart_imp <- varImp(rpart_fit)$importance\n",
    "rpart_imp <- rpart_imp[order(-), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
